{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6910_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b6df90f645b47a3816870ef25aa4556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0184890c92b049859922e6618f5c690e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4acc109ebdad4384a20bb64e34f85e5c",
              "IPY_MODEL_0e404dba42284914916c71d9a49bb514"
            ]
          }
        },
        "0184890c92b049859922e6618f5c690e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4acc109ebdad4384a20bb64e34f85e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_49f8de8330034c79bb56294a6e4c58f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23f95e503e9648a1a54241ab69eb22d9"
          }
        },
        "0e404dba42284914916c71d9a49bb514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_249609f01f3941eba5a3d369f2ca43a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d697c50e96b94bbf908f523f6d095760"
          }
        },
        "49f8de8330034c79bb56294a6e4c58f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23f95e503e9648a1a54241ab69eb22d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "249609f01f3941eba5a3d369f2ca43a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d697c50e96b94bbf908f523f6d095760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwBqsxQoczw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b755f3c1-d97c-491d-ae14-c93ef4091050"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ae/79374d2b875e638090600eaa2a423479865b7590c53fb78e8ccf6a64acb1/wandb-0.10.22-py2.py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 48.9MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 48.6MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.0MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.0.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=72ed10482f9a758f04e0a782767322cead2fc6a779b02d0512aeae8ccde57748\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=462bfc70d85beccf25e5b4a47a64bec3f363bd21ae148854249838d47a675f8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, GitPython, configparser, shortuuid, sentry-sdk, subprocess32, pathtools, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ods22NlvpAfG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4e824b3f-1e26-477b-b55c-73aa7e218711"
      },
      "source": [
        "import wandb\r\n",
        "wandb.login()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edFb4Fygf0hv"
      },
      "source": [
        "#Question 1 (2 Marks)\r\n",
        "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use \"from keras.datasets import fashion_mnist\" for getting the fashion mnist dataset.\r\n",
        "\r\n",
        "﻿"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9ygxnE_ctp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "47ba3fff-3438-4a47-eac5-430afaca3688"
      },
      "source": [
        "from keras.datasets import fashion_mnist\r\n",
        "from matplotlib import pyplot\r\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "label = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "for i in range(10):\r\n",
        "   wandb.init(project=\"cs6910-assignment01\")\r\n",
        "   wandb.run.name = \"Q1_run_{}\".format(i+1)\r\n",
        "   for j in range(30):\r\n",
        "     if y_train[j] == i:\r\n",
        "       wandb.log({\"examples\": [wandb.Image(X_train[j], caption=label[i])]})\r\n",
        "       break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Problem at: <ipython-input-3-a659662e0ecd> 7 <module>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a659662e0ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m    \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cs6910-assignment01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m    \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Q1_run_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# initiate run (stats and metadata probing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mrun_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_obj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_obj_offline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_run_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_run_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_run_start\u001b[0;34m(self, run_pb)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mrun_start\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     ) -> Optional[pb.Result]:\n\u001b[0;32m--> 527\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_communicate_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_Future\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mis_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_set\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DMgxgi4PRGt"
      },
      "source": [
        "# Question 2 (10 Marks)\r\n",
        "\r\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\r\n",
        "\r\n",
        "Your code should be flexible so that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3thNIX-cOIA3"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "def sigmoid(z):\r\n",
        "  g = 1/(1+np.exp(-z))\r\n",
        "  return g\r\n",
        "\r\n",
        "def tanh(z):\r\n",
        "  g = np.tanh(z)\r\n",
        "  return g\r\n",
        "\r\n",
        "def relu(z):\r\n",
        "  return np.maximum(0,z)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_qU08dQy3f5"
      },
      "source": [
        "def softmax(x):\r\n",
        "    e_x = np.exp(x - np.max(x))\r\n",
        "    return e_x / e_x.sum()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXeouW-aXGsb"
      },
      "source": [
        "def initialize(initializer, size1, size2):\r\n",
        "  if(initializer == \"random\"):\r\n",
        "     W = np.random.randn(size1, size2) * 0.01\r\n",
        "     return W\r\n",
        "\r\n",
        "  if(initializer == \"Xavier\"):\r\n",
        "     W = np.random.randn(size1, size2) * np.sqrt(1/size2)\r\n",
        "     return W\r\n",
        "\r\n",
        "  print(\"Enter the name of initializer correctly\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6P2Su_1dv30"
      },
      "source": [
        "def linear_forward(H, W, b):\r\n",
        "  W = np.asarray(W)\r\n",
        "  H = np.reshape(H,(H.shape[0],-1))\r\n",
        "  A = np.dot(W,H) + b \r\n",
        "  cache = (H, W, b)\r\n",
        "  \r\n",
        "  return A, cache"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zXc1-js-dgL"
      },
      "source": [
        "def initialize_Wb_matrix(X, num_hidden, size_hidden, initializer):\r\n",
        "  layer_dims = [X.shape[0]]\r\n",
        "  for l in range(0, num_hidden):\r\n",
        "    layer_dims.append(size_hidden)\r\n",
        "  layer_dims.append(10)   \r\n",
        "  np.random.seed(3)\r\n",
        "  Wb_matrix = {}\r\n",
        "  update = {}\r\n",
        "  grads = {}\r\n",
        "  L = len(layer_dims)            # number of layers in the network\r\n",
        "\r\n",
        "  for l in range(1,L):\r\n",
        "    Wb_matrix['W' + str(l)] = initialize(initializer, layer_dims[l], layer_dims[l-1])\r\n",
        "    update['W' + str(l)] = np.zeros((layer_dims[l], layer_dims[l-1]))\r\n",
        "    Wb_matrix['b' + str(l)] = np.zeros((layer_dims[l], 1))\r\n",
        "    update['b' + str(l)] = np.zeros((layer_dims[l], 1))\r\n",
        "    grads['dW' + str(l)] = np.zeros((layer_dims[l], layer_dims[l-1]))\r\n",
        "    grads['db' + str(l)] = np.zeros((layer_dims[l], 1))\r\n",
        "  return Wb_matrix, update, grads"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7zsskSyU1ZO"
      },
      "source": [
        "def activation_forward(H_prev, W, b, activation):\r\n",
        "  A, linear_cache = linear_forward(H_prev, W, b)\r\n",
        "  activation_cache = A\r\n",
        "  if activation == 'relu':\r\n",
        "    H = relu(A)\r\n",
        "  elif activation == 'sigmoid':\r\n",
        "    H = sigmoid(A)\r\n",
        "  elif activation =='tanh':\r\n",
        "    H = tanh(A)\r\n",
        "  elif activation == 'softmax':\r\n",
        "    H = softmax(A)\r\n",
        "  \r\n",
        "  return H, activation_cache, linear_cache"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DITldZOSHNt2"
      },
      "source": [
        "def forward_propagation(X, Wb_matrix, activation):\r\n",
        "    H = X\r\n",
        "    L = int((len(Wb_matrix)/2))\r\n",
        "    A_caches = []\r\n",
        "    H_caches = [H]\r\n",
        "    for l in range(1, L):\r\n",
        "        H_prev = H \r\n",
        "        H, A_cache, linear_cache = activation_forward(H_prev, Wb_matrix['W{:d}'.format(l)], Wb_matrix['b{:d}'.format(l)], activation)\r\n",
        "        A_caches.append(A_cache)\r\n",
        "        H_caches.append(H)\r\n",
        "    HL, AL, linear_cache = activation_forward(H, Wb_matrix['W%d' % L], Wb_matrix['b%d' % L], activation='softmax')\r\n",
        "    A_caches.append(AL)\r\n",
        "    H_caches.append(HL)\r\n",
        "    return HL, H_caches, A_caches"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6hlMq4saR14"
      },
      "source": [
        "# Question 3 (18 Marks)\r\n",
        "\r\n",
        "Implement the backpropagation algorithm with support for the following optimisation functions \r\n",
        "\r\n",
        "- sgd\r\n",
        "- momentum based gradient descent\r\n",
        "- nesterov accelerated gradient descent\r\n",
        "- rmsprop\r\n",
        "- adam\r\n",
        "- nadam\r\n",
        "\r\n",
        "(12 marks for the backpropagation framework and 2 marks for each of the optimisation algorithms above)\r\n",
        "\r\n",
        "We will check the code for implementation and ease of use (e.g., how easy it is to add a new optimisation algorithm such as Eve). Note that the code should be flexible enough to work with different batch sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b3Qc4pcN2iD"
      },
      "source": [
        "def one_hot_encoding(l, L):\r\n",
        "  import numpy\r\n",
        "  e = []\r\n",
        "  for i in range(L):\r\n",
        "    if i == l:\r\n",
        "      e.append(1)\r\n",
        "    else:\r\n",
        "      e.append(0)\r\n",
        "  e_y = np.asarray(e)\r\n",
        "  return e_y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6UpazPvcV6c"
      },
      "source": [
        "def deriv_activ(z, activation):\r\n",
        "  if(activation == \"relu\"):\r\n",
        "    z[z<=0] = 0\r\n",
        "    z[z>0] = 1\r\n",
        "    return z\r\n",
        "\r\n",
        "  elif(activation == \"sigmoid\"):\r\n",
        "    g_deriv = sigmoid(z) * (1 - sigmoid(z))\r\n",
        "    return g_deriv\r\n",
        "  \r\n",
        "  elif(activation == \"tanh\"):\r\n",
        "    deriv = 1 - (tanh(z)) ** 2\r\n",
        "    return deriv"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGp9a-HAVJaZ"
      },
      "source": [
        "def back_propagation(H_caches, A_caches, Wb_matrix, y_hat, y, activation, weight_decay,loss):\r\n",
        "  e_y = []\r\n",
        "  L = int((len(Wb_matrix)/2))\r\n",
        "  num_train = y_hat.shape[1]\r\n",
        "  num_classes = y_hat.shape[0]\r\n",
        "  for j in range(num_train):\r\n",
        "    e_y.append(one_hot_encoding(y[j],num_classes))\r\n",
        "  e_y = np.reshape(e_y,(num_classes,num_train))\r\n",
        "  if loss == \"cross_entropy\":\r\n",
        "    da = -(e_y - y_hat)\r\n",
        "  elif loss == \"mse\":\r\n",
        "    da = (y_hat - e_y)*y_hat - y_hat*(np.dot((y_hat-y).T, y_hat))\r\n",
        "  da = -(e_y - y_hat)\r\n",
        "  grads = {}\r\n",
        "  \r\n",
        "  for k in reversed(range(1,L+1)):\r\n",
        "    dW = np.matmul(da, np.transpose(H_caches[k-1])) + 2*weight_decay*Wb_matrix['W{:d}'.format(k)]\r\n",
        "    db = da\r\n",
        "    if k != 1:\r\n",
        "      dh = np.dot(Wb_matrix['W{:d}'.format(k)].T, da)\r\n",
        "      da = np.multiply(dh, deriv_activ(A_caches[k-2], activation))\r\n",
        "    grads[\"dW\" + str(k)] = dW\r\n",
        "    grads[\"db\" + str(k)] = db\r\n",
        "  \r\n",
        "  return grads"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l16UXHD_YsCH"
      },
      "source": [
        "def sgd(Wb_matrix, grads, eta,L):\r\n",
        "  for l in range(L):\r\n",
        "    Wb_matrix['W' + str(l+1)] = Wb_matrix['W' + str(l+1)] - eta * grads[\"dW\" + str(l+1)]\r\n",
        "    Wb_matrix['b' + str(l+1)] = Wb_matrix['b' + str(l+1)] - eta * grads[\"db\" + str(l+1)]\r\n",
        "  return Wb_matrix\r\n",
        "\r\n",
        "def momentum(Wb_matrix, grads, eta, gamma, update,L):\r\n",
        "  for l in range(L):\r\n",
        "    update['W' + str(l+1)] = (gamma * update['W' + str(l+1)]) + eta * grads['dW' + str(l+1)]\r\n",
        "    Wb_matrix['W' + str(l+1)] = Wb_matrix['W' + str(l+1)] - update['W' + str(l+1)]\r\n",
        "\r\n",
        "    update[\"b\" + str(l+1)] = (gamma * update[\"b\" + str(l+1)]) + eta * grads[\"db\" + str(l+1)]\r\n",
        "    Wb_matrix[\"b\" + str(l+1)] = Wb_matrix[\"b\" + str(l+1)] - update[\"b\" + str(l+1)]\r\n",
        "  \r\n",
        "  return Wb_matrix, update\r\n",
        "\r\n",
        "def nag(Wb_matrix,eta,gamma, update, L):\r\n",
        "  Wb_matrix_temp= {}\r\n",
        "  for l in range(L):\r\n",
        "    update['W' + str(l+1)] = (gamma * update['W' + str(l+1)])\r\n",
        "    Wb_matrix_temp['W' + str(l+1)] = Wb_matrix['W' + str(l+1)] - update['W' + str(l+1)]\r\n",
        "\r\n",
        "    update[\"b\" + str(l+1)] = (gamma * update[\"b\" + str(l+1)])\r\n",
        "    Wb_matrix_temp[\"b\" + str(l+1)] = Wb_matrix[\"b\" + str(l+1)] - update[\"b\" + str(l+1)]\r\n",
        "\r\n",
        "  return Wb_matrix_temp, update\r\n",
        "\r\n",
        "def rmsprop(Wb_matrix, eta, update ,beta1, eps, grads, L):\r\n",
        "  for l in range(L):\r\n",
        "    update['W' + str(l+1)] = beta1 * update['W' + str(l+1)] + (1-beta1) * grads['dW' + str(l+1)]**2\r\n",
        "    update[\"b\" + str(l+1)] = beta1 * update[\"b\" + str(l+1)] + (1-beta1) * grads[\"db\" + str(l+1)]**2\r\n",
        "    Wb_matrix['W' + str(l+1)] = Wb_matrix['W' + str(l+1)] - (eta/np.sqrt(update['W' + str(l+1)]+eps)) * grads['dW' + str(l+1)]\r\n",
        "    Wb_matrix[\"b\" + str(l+1)] = Wb_matrix[\"b\" + str(l+1)] - (eta/np.sqrt(update['b' + str(l+1)]+eps)) * grads['db' + str(l+1)]\r\n",
        "  return Wb_matrix, update\r\n",
        "  \r\n",
        "def adam(Wb_matrix, eta, beta1, beta2, update, v_n, eps, grads, L,i):\r\n",
        "  import math\r\n",
        "  m_hat = update.copy()\r\n",
        "  v_hat = update.copy()\r\n",
        "  for l in range(L):\r\n",
        "    update['W' + str(l+1)] = beta1 * update['W' + str(l+1)] + (1-beta1) * grads['dW' + str(l+1)]\r\n",
        "    update['b' + str(l+1)] = beta1 * update['b' + str(l+1)] + (1-beta1) * grads['db' + str(l+1)]\r\n",
        "    \r\n",
        "    v_n['W' + str(l+1)] = beta2 * v_n['W' + str(l+1)] + (1-beta2) * grads['dW' + str(l+1)]**2\r\n",
        "    v_n[\"b\" + str(l+1)] = beta2 * v_n[\"b\" + str(l+1)] + (1-beta2) * grads['db' + str(l+1)]**2\r\n",
        "    \r\n",
        "    m_hat['W' + str(l+1)] = update['W' + str(l+1)]/(1-math.pow(beta1,i+1))\r\n",
        "    m_hat['b' + str(l+1)] = update['b' + str(l+1)]/(1-math.pow(beta1,i+1))\r\n",
        "\r\n",
        "    v_hat['W' + str(l+1)] = v_n['W' + str(l+1)]/(1-math.pow(beta2,i+1))\r\n",
        "    v_hat['b' + str(l+1)] = v_n['b' + str(l+1)]/(1-math.pow(beta2,i+1))\r\n",
        "\r\n",
        "\r\n",
        "    Wb_matrix['W' + str(l+1)] = Wb_matrix['W' + str(l+1)] - (eta/(np.sqrt(v_hat['W' + str(l+1)]+eps)))* m_hat['W' + str(l+1)]\r\n",
        "    Wb_matrix[\"b\" + str(l+1)] = Wb_matrix[\"b\" + str(l+1)] - (eta/(np.sqrt(v_hat['b' + str(l+1)]+eps)))* m_hat['b' + str(l+1)]\r\n",
        "\r\n",
        " \r\n",
        "  return Wb_matrix, update, v_n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe0gM5BCCV8p"
      },
      "source": [
        "# Question 4 (10 Marks)\r\n",
        "\r\n",
        "Use the sweep functionality provided by wandb to find the best values for the hyperparameters listed below. Use the standard train/test split of fashion_mnist (use (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()).  Keep 10% of the training data aside as validation data for this hyperparameter search. Here are some suggestions for different values to try for hyperparameters. As you can quickly see that this leads to an exponential number of combinations. You will have to think about strategies to do this hyperparameter search efficiently. Check out the options provided by wandb.sweep and write down what strategy you chose and why.\r\n",
        "\r\n",
        "- number of epochs: 5, 10\r\n",
        "- number of hidden layers:  3, 4, 5\r\n",
        "- size of every hidden layer:  32, 64, 128\r\n",
        "- weight decay (L2 regularisation): 0, 0.0005,  0.5\r\n",
        "- learning rate: 1e-3, 1 e-4 \r\n",
        "- optimizer:  sgd, momentum, nesterov, rmsprop, adam, nadam\r\n",
        "- batch size: 16, 32, 64\r\n",
        "- weight initialisation: random, Xavier\r\n",
        "- activation functions: sigmoid, tanh, ReLU\r\n",
        "\r\n",
        "wandb will automatically generate the following plots. Paste these plots below using the \"Add Panel to Report\" feature. Make sure you use meaningful names for each sweep (e.g. hl_3_bs_16_ac_tanh to indicate that there were 3 hidden layers, batch size was 16 and activation function was ReLU) instead of using the default names (whole-sweep, kind-sweep) given by wandb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo0kRUHIQMDO"
      },
      "source": [
        "def swp():\r\n",
        "  from keras.datasets import fashion_mnist\r\n",
        "  from matplotlib import pyplot\r\n",
        "  import numpy as np\r\n",
        "  import math\r\n",
        "  import random\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  import seaborn as sns\r\n",
        "  from sklearn.model_selection import train_test_split\r\n",
        "  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "  X_train_flatten = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))/255.0\r\n",
        "  \r\n",
        "  X_test_flatten = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))/255.0\r\n",
        "  X_test_flatten = X_test_flatten.T\r\n",
        "\r\n",
        "  X_train_flatten, X_val, y_train, y_val = train_test_split( X_train_flatten, y_train, test_size=0.1, random_state=42)\r\n",
        "  X_train_flatten = X_train_flatten.T\r\n",
        "  X_val = X_val.T\r\n",
        "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "  num_train = int(0.9*X_train.shape[0])\r\n",
        "  num_val = int(0.1*X_train.shape[0])\r\n",
        " \r\n",
        "  hyperparameter_defaults = dict(\r\n",
        "      num_hidden = 4,\r\n",
        "      size_hidden = 128,\r\n",
        "      weight_decay = 0,\r\n",
        "      optimizer = 'nag',\r\n",
        "      initializer = 'Xavier',\r\n",
        "      activation = 'relu',\r\n",
        "      batch_size = 16,\r\n",
        "      learning_rate = 0.001,\r\n",
        "      max_epoch = 10,\r\n",
        "      loss_func = 'mse'\r\n",
        "      )\r\n",
        "\r\n",
        "  \r\n",
        "  wandb.init(project=\"cs6910-assignment01\", config=hyperparameter_defaults)\r\n",
        "  config = wandb.config\r\n",
        "  wandb.run.name = \"{}_hl{}_bs_{}_ac_{}\".format(config.loss_func, config.num_hidden,config.batch_size, config.activation)\r\n",
        "  L = config.num_hidden+1\r\n",
        "  beta1 = 0.9\r\n",
        "  beta2 = 0.999\r\n",
        "  eps = 1e-8\r\n",
        "  gamma = 0.9\r\n",
        "\r\n",
        "\r\n",
        "  Wb_matrix, update, grad_initial = initialize_Wb_matrix(X_train_flatten, config.num_hidden , config.size_hidden ,config.initializer)\r\n",
        "  #initializing parameters in adam optimization to zero dictionary\r\n",
        "  v = update.copy()\r\n",
        "  m_hat = update.copy()\r\n",
        "  v_hat = update.copy()\r\n",
        "\r\n",
        "  \r\n",
        "  for i in range(config.max_epoch):\r\n",
        "    loss = 0\r\n",
        "    val_loss = 0\r\n",
        "    count = 0\r\n",
        "    grads = grad_initial\r\n",
        "    print(\"Epoch:\", i+1)\r\n",
        "    for j in range(num_train):\r\n",
        "      train_ip= np.reshape(X_train_flatten[:,j], (-1, 1)) \r\n",
        "      y_hat, H_caches, A_caches = forward_propagation(train_ip, Wb_matrix ,config.activation)\r\n",
        "      if(y_train[j]==np.argmax(y_hat)):\r\n",
        "        count = count + 1; \r\n",
        "\r\n",
        "      if (j+1)%config.batch_size == 0  :\r\n",
        "        if config.optimizer == 'nag':\r\n",
        "          Wb_matrix, update = nag(Wb_matrix, config.learning_rate,gamma, update, L)\r\n",
        "        elif config.optimizer == 'nadam':\r\n",
        "          Wb_matrix, update = nag(Wb_matrix, config.learning_rate,gamma, update, L)\r\n",
        "\r\n",
        "      grad = back_propagation(H_caches, A_caches, Wb_matrix, y_hat, [y_train[j]], config.activation, config.weight_decay,config.loss_func)\r\n",
        "      for l in range(L):\r\n",
        "        grads['dW' + str(l+1)] = grads['dW' + str(l+1)] + grad['dW' + str(l+1)] \r\n",
        "        grads['db' + str(l+1)] = grads['db' + str(l+1)] + grad['db' + str(l+1)] \r\n",
        "\r\n",
        "\r\n",
        "      if (j+1)%config.batch_size == 0 : \r\n",
        "        for l in range(L):\r\n",
        "          grads['dW' + str(l+1)] = grads['dW' + str(l+1)]/config.batch_size\r\n",
        "          grads['db' + str(l+1)] = grads['db' + str(l+1)]/config.batch_size\r\n",
        "        if config.optimizer == 'sgd':\r\n",
        "          Wb_matrix = sgd(Wb_matrix, grads, config.learning_rate,L)\r\n",
        "        elif config.optimizer == 'momentum':\r\n",
        "          Wb_matrix,update = momentum(Wb_matrix,grads,config.learning_rate,gamma,update,L)\r\n",
        "        elif config.optimizer == 'nag':\r\n",
        "          Wb_matrix,update = momentum(Wb_matrix,grads,config.learning_rate,gamma,update,L)\r\n",
        "        elif config.optimizer == 'rmsprop':\r\n",
        "          Wb_matrix, update = rmsprop(Wb_matrix, config.learning_rate, update,  beta1, eps, grads, L)\r\n",
        "        elif config.optimizer == 'adam':\r\n",
        "          Wb_matrix, update,v = adam(Wb_matrix, config.learning_rate, beta1, beta2, update, v, eps, grads, L, i+1)\r\n",
        "        elif config.optimizer == 'nadam':\r\n",
        "          Wb_matrix, update,v = adam(Wb_matrix, config.learning_rate, beta1, beta2, update, v, eps, grads, L, i+1)    \r\n",
        "      if config.loss_func == 'cross_entropy':\r\n",
        "        loss = loss - (1/num_train)*math.log(y_hat[y_train[j]])\r\n",
        "      elif config.loss_func == 'mse':\r\n",
        "        loss = loss + (1/num_train)*(np.argmax(y_hat) - y_train[j])**2\r\n",
        "    \r\n",
        "    y_hat_val, H_caches_val, A_caches_val = forward_propagation(X_val, Wb_matrix ,config.activation)\r\n",
        "    count_val = np.sum(np.argmax(y_hat_val, axis = 0)== y_val)\r\n",
        "    \r\n",
        "    for j in range(num_val):\r\n",
        "      val_ip= np.reshape(X_val[:,j], (-1, 1)) \r\n",
        "      y_hat_val, H_caches_val, A_caches_val = forward_propagation(val_ip, Wb_matrix ,config.activation)\r\n",
        "      if config.loss_func == 'cross_entropy':\r\n",
        "        val_loss = val_loss - (1/num_val)*math.log(y_hat_val[int(y_val[j])])\r\n",
        "      elif config.loss_func == 'mse':\r\n",
        "        val_loss = val_loss + (1/num_val)*(np.argmax(y_hat_val) - y_val[j])**2\r\n",
        "\r\n",
        "    accuracy = 100*count/num_train\r\n",
        "    val_accuracy = 100*count_val/num_val\r\n",
        "\r\n",
        "    print(\"     Loss\", loss)\r\n",
        "    print(\"     Accuracy\",accuracy)\r\n",
        "    print(\"     Validation Loss\", val_loss)\r\n",
        "    print(\"     Validation Accuracy\", val_accuracy)\r\n",
        "\r\n",
        "    metrics = {'epoch':i, 'val_accuracy': val_accuracy, 'val_loss': val_loss, 'accuracy': accuracy, 'loss': loss}\r\n",
        "    wandb.log(metrics)\r\n",
        "\r\n",
        "  y_hat_test, H_caches_test, A_caches_test = forward_propagation(X_test_flatten, Wb_matrix ,config.activation)\r\n",
        "  wandb.log({\"Confusion_Matrix\" : wandb.plot.confusion_matrix(\r\n",
        "                        probs=None,\r\n",
        "                        y_true=y_test,\r\n",
        "                        preds=np.argmax(y_hat_test, axis = 0),\r\n",
        "                        class_names=class_names)})\r\n",
        "  \r\n",
        "\r\n",
        "  wandb.run.finish()\r\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b6df90f645b47a3816870ef25aa4556",
            "0184890c92b049859922e6618f5c690e",
            "4acc109ebdad4384a20bb64e34f85e5c",
            "0e404dba42284914916c71d9a49bb514",
            "49f8de8330034c79bb56294a6e4c58f2",
            "23f95e503e9648a1a54241ab69eb22d9",
            "249609f01f3941eba5a3d369f2ca43a7",
            "d697c50e96b94bbf908f523f6d095760"
          ]
        },
        "id": "V0avfDbFiBVx",
        "outputId": "99a2c18d-a76d-432d-ba8a-bebac5bd5384"
      },
      "source": [
        "swp()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2zuw12df) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 4079<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b6df90f645b47a3816870ef25aa4556",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210313_171831-2zuw12df/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210313_171831-2zuw12df/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lunar-disco-83</strong>: <a href=\"https://wandb.ai/karthik21/cs6910-assignment01/runs/2zuw12df\" target=\"_blank\">https://wandb.ai/karthik21/cs6910-assignment01/runs/2zuw12df</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2zuw12df). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">glowing-darkness-84</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karthik21/cs6910-assignment01\" target=\"_blank\">https://wandb.ai/karthik21/cs6910-assignment01</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/karthik21/cs6910-assignment01/runs/3jqxsu4u\" target=\"_blank\">https://wandb.ai/karthik21/cs6910-assignment01/runs/3jqxsu4u</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210313_171913-3jqxsu4u</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "     Loss 2.8904629629632863\n",
            "     Accuracy 74.18703703703704\n",
            "     Validation Loss 2.2048333333333185\n",
            "     Validation Accuracy 82.61666666666666\n",
            "Epoch: 2\n",
            "     Loss 2.0621481481481645\n",
            "     Accuracy 83.66481481481482\n",
            "     Validation Loss 1.8736666666666528\n",
            "     Validation Accuracy 85.48333333333333\n",
            "Epoch: 3\n",
            "     Loss 1.9081111111111113\n",
            "     Accuracy 85.42962962962963\n",
            "     Validation Loss 1.6769999999999898\n",
            "     Validation Accuracy 86.8\n",
            "Epoch: 4\n",
            "     Loss 1.791759259259267\n",
            "     Accuracy 86.48703703703704\n",
            "     Validation Loss 1.645999999999991\n",
            "     Validation Accuracy 87.11666666666666\n",
            "Epoch: 5\n",
            "     Loss 1.7101666666666786\n",
            "     Accuracy 87.21666666666667\n",
            "     Validation Loss 1.5653333333333277\n",
            "     Validation Accuracy 87.41666666666667\n",
            "Epoch: 6\n",
            "     Loss 1.6202222222222424\n",
            "     Accuracy 87.88333333333334\n",
            "     Validation Loss 1.5464999999999938\n",
            "     Validation Accuracy 87.75\n",
            "Epoch: 7\n",
            "     Loss 1.5779074074074284\n",
            "     Accuracy 88.34814814814816\n",
            "     Validation Loss 1.5353333333333283\n",
            "     Validation Accuracy 87.95\n",
            "Epoch: 8\n",
            "     Loss 1.5134629629629863\n",
            "     Accuracy 88.82407407407408\n",
            "     Validation Loss 1.4918333333333285\n",
            "     Validation Accuracy 88.25\n",
            "Epoch: 9\n",
            "     Loss 1.4707777777778022\n",
            "     Accuracy 89.20370370370371\n",
            "     Validation Loss 1.5234999999999945\n",
            "     Validation Accuracy 88.16666666666667\n",
            "Epoch: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfKEScFrjZVA"
      },
      "source": [
        "import wandb\r\n",
        "\r\n",
        "sweep_config = {\r\n",
        "  \"name\": \"My Sweep\",\r\n",
        "  \"method\": \"grid\",\r\n",
        "  \"project\": \"cs6910-assignment01\",\r\n",
        "  \"metric\":{\r\n",
        "      \"name\":\"val_accuracy\",\r\n",
        "      \"goal\":\"maximize\"\r\n",
        "  },\r\n",
        "  \"parameters\": {\r\n",
        "        \"max_epoch\": {\r\n",
        "            \"values\": [10]\r\n",
        "        },\r\n",
        "        \"num_hidden\": {\r\n",
        "            \"values\":[5]\r\n",
        "        }, \r\n",
        "        \"size_hidden\": {\r\n",
        "            \"values\":[128]\r\n",
        "        },\r\n",
        "        \"weight_decay\":{\r\n",
        "            \"values\":[0, 0.0005]\r\n",
        "        },\r\n",
        "        \"learning_rate\":{\r\n",
        "            \"values\":[0.001]\r\n",
        "        },\r\n",
        "        \"batch_size\": {\r\n",
        "            \"values\":[16]\r\n",
        "        },  \r\n",
        "        \"optimizer\": {\r\n",
        "            \"values\":['adam', 'nadam']\r\n",
        "        },\r\n",
        "        \"initializer\": {\r\n",
        "            \"values\":['Xavier']\r\n",
        "        },\r\n",
        "        \"activation\":{\r\n",
        "            \"values\": ['relu']\r\n",
        "        },\r\n",
        "        \"loss_func\":{\r\n",
        "            \"values\": ['cross_entropy']\r\n",
        "        }\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXXTVz-EB8iT"
      },
      "source": [
        "import wandb\r\n",
        "\r\n",
        "sweep_config = {\r\n",
        "  \"name\": \"Loss_compare\",\r\n",
        "  \"method\": \"grid\",\r\n",
        "  \"project\": \"cs6910-assignment01\",\r\n",
        "  \"metric\":{\r\n",
        "      \"name\":\"val_accuracy\",\r\n",
        "      \"goal\":\"maximize\"\r\n",
        "  },\r\n",
        "  \"parameters\": {\r\n",
        "        \"max_epoch\": {\r\n",
        "            \"values\":[10]\r\n",
        "        },\r\n",
        "        \"num_hidden\": {\r\n",
        "            \"values\":[5]\r\n",
        "        }, \r\n",
        "        \"size_hidden\": {\r\n",
        "            \"values\":[64]\r\n",
        "        },\r\n",
        "        \"weight_decay\":{\r\n",
        "            \"values\":[0]\r\n",
        "        },\r\n",
        "        \"learning_rate\":{\r\n",
        "            \"values\":[0.001]\r\n",
        "        },\r\n",
        "        \"batch_size\": {\r\n",
        "            \"values\":[16]\r\n",
        "        },  \r\n",
        "        \"optimizer\": {\r\n",
        "            \"values\":['adam']\r\n",
        "        },\r\n",
        "        \"initializer\": {\r\n",
        "            \"values\":['Xavier']\r\n",
        "        },\r\n",
        "        \"activation\":{\r\n",
        "            \"values\": ['relu']\r\n",
        "        },\r\n",
        "        \"loss_func\":{\r\n",
        "            \"values\": ['mse']\r\n",
        "        }\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxqHmkN03OBv"
      },
      "source": [
        "# MNIST DATASET\r\n",
        "\r\n",
        "Based on your learnings above, give me 3 recommendations for what would work for the MNIST dataset (not Fashion-MNIST). Just to be clear, I am asking you to take your learnings based on extensive experimentation with one dataset and see if these learnings help on another dataset. If I give you a budget of running only 3 hyperparameter configurations as opposed to the large number of experiments you have run above then which 3 would you use and why. Report the accuracies that you obtain using these 3 configurations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQi3AJd2MuD"
      },
      "source": [
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzjYjqTiH56K"
      },
      "source": [
        "def mnist_swp():\r\n",
        "  from keras.datasets import mnist\r\n",
        "  from matplotlib import pyplot\r\n",
        "  import numpy as np\r\n",
        "  import math\r\n",
        "  import random\r\n",
        "  from sklearn.metrics import confusion_matrix\r\n",
        "  import seaborn as sns\r\n",
        "  from sklearn.model_selection import train_test_split\r\n",
        "  (X_train, y_train), (X_test, y_test) = mnist.load_data()\r\n",
        "  X_train_flatten = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]*X_train.shape[2]))/255.0\r\n",
        "  \r\n",
        "  X_test_flatten = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]*X_test.shape[2]))/255.0\r\n",
        "  X_test_flatten = X_test_flatten.T\r\n",
        "\r\n",
        "  X_train_flatten, X_val, y_train, y_val = train_test_split( X_train_flatten, y_train, test_size=0.1, random_state=42)\r\n",
        "  X_train_flatten = X_train_flatten.T\r\n",
        "  X_val = X_val.T\r\n",
        "  class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "  num_train = int(0.9*X_train.shape[0])\r\n",
        "  num_val = int(0.1*X_train.shape[0])\r\n",
        " \r\n",
        "  hyperparameter_defaults = dict(\r\n",
        "      num_hidden = 5,\r\n",
        "      size_hidden = 64,\r\n",
        "      weight_decay = 0.0005,\r\n",
        "      optimizer = 'adam',\r\n",
        "      initializer = 'Xavier',\r\n",
        "      activation = 'relu',\r\n",
        "      batch_size = 16,\r\n",
        "      learning_rate = 0.001,\r\n",
        "      max_epoch = 10,\r\n",
        "      loss_func = 'cross_entropy'\r\n",
        "      )\r\n",
        "\r\n",
        "  \r\n",
        "  wandb.init(project=\"cs6910-assignment01\", config=hyperparameter_defaults)\r\n",
        "  config = wandb.config\r\n",
        "  wandb.run.name = \"MNIST_hl{}_bs_{}_ac_{}\".format(config.num_hidden,config.batch_size, config.activation)\r\n",
        "  L = config.num_hidden+1\r\n",
        "  beta1 = 0.9\r\n",
        "  beta2 = 0.999\r\n",
        "  eps = 1e-8\r\n",
        "  gamma = 0.9\r\n",
        "\r\n",
        "\r\n",
        "  Wb_matrix, update, grad_initial = initialize_Wb_matrix(X_train_flatten, config.num_hidden , config.size_hidden ,config.initializer)\r\n",
        "  #initializing parameters in adam optimization to zero dictionary\r\n",
        "  v = update.copy()\r\n",
        "  m_hat = update.copy()\r\n",
        "  v_hat = update.copy()\r\n",
        "\r\n",
        "  \r\n",
        "  for i in range(config.max_epoch):\r\n",
        "    loss = 0\r\n",
        "    val_loss = 0\r\n",
        "    count = 0\r\n",
        "    grads = grad_initial\r\n",
        "    print(\"Epoch:\", i+1)\r\n",
        "    for j in range(num_train):\r\n",
        "      train_ip= np.reshape(X_train_flatten[:,j], (-1, 1)) \r\n",
        "      y_hat, H_caches, A_caches = forward_propagation(train_ip, Wb_matrix ,config.activation)\r\n",
        "      if(y_train[j]==np.argmax(y_hat)):\r\n",
        "        count = count + 1; \r\n",
        "\r\n",
        "      if (j+1)%config.batch_size == 0  :\r\n",
        "        if config.optimizer == 'nag':\r\n",
        "          Wb_matrix, update = nag(Wb_matrix, config.learning_rate,gamma, update, L)\r\n",
        "        elif config.optimizer == 'nadam':\r\n",
        "          Wb_matrix, update = nag(Wb_matrix, config.learning_rate,gamma, update, L)\r\n",
        "\r\n",
        "      grad = back_propagation(H_caches, A_caches, Wb_matrix, y_hat, [y_train[j]], config.activation, config.weight_decay,config.loss_func)\r\n",
        "      for l in range(L):\r\n",
        "        grads['dW' + str(l+1)] = grads['dW' + str(l+1)] + grad['dW' + str(l+1)] \r\n",
        "        grads['db' + str(l+1)] = grads['db' + str(l+1)] + grad['db' + str(l+1)] \r\n",
        "\r\n",
        "\r\n",
        "      if (j+1)%config.batch_size == 0 : \r\n",
        "        for l in range(L):\r\n",
        "          grads['dW' + str(l+1)] = grads['dW' + str(l+1)]/config.batch_size\r\n",
        "          grads['db' + str(l+1)] = grads['db' + str(l+1)]/config.batch_size\r\n",
        "        if config.optimizer == 'sgd':\r\n",
        "          Wb_matrix = sgd(Wb_matrix, grads, config.learning_rate,L)\r\n",
        "        elif config.optimizer == 'momentum':\r\n",
        "          Wb_matrix,update = momentum(Wb_matrix,grads,config.learning_rate,gamma,update,L)\r\n",
        "        elif config.optimizer == 'nag':\r\n",
        "          Wb_matrix,update = momentum(Wb_matrix,grads,config.learning_rate,gamma,update,L)\r\n",
        "        elif config.optimizer == 'rmsprop':\r\n",
        "          Wb_matrix, update = rmsprop(Wb_matrix, config.learning_rate, update,  beta1, eps, grads, L)\r\n",
        "        elif config.optimizer == 'adam':\r\n",
        "          Wb_matrix, update,v = adam(Wb_matrix, config.learning_rate, beta1, beta2, update, v, eps, grads, L, i+1)\r\n",
        "        elif config.optimizer == 'nadam':\r\n",
        "          Wb_matrix, update,v = adam(Wb_matrix, config.learning_rate, beta1, beta2, update, v, eps, grads, L, i+1)    \r\n",
        "      if config.loss_func == 'cross_entropy':\r\n",
        "        loss = loss - (1/num_train)*math.log(y_hat[y_train[j]])\r\n",
        "      elif config.loss_func == 'mse':\r\n",
        "        loss = loss + (1/num_train)*(np.argmax(y_hat) - y_train[j])**2\r\n",
        "    \r\n",
        "    y_hat_val, H_caches_val, A_caches_val = forward_propagation(X_val, Wb_matrix ,config.activation)\r\n",
        "    count_val = np.sum(np.argmax(y_hat_val, axis = 0)== y_val)\r\n",
        "    \r\n",
        "    for j in range(num_val):\r\n",
        "      val_ip= np.reshape(X_val[:,j], (-1, 1)) \r\n",
        "      y_hat_val, H_caches_val, A_caches_val = forward_propagation(val_ip, Wb_matrix ,config.activation)\r\n",
        "      if config.loss_func == 'cross_entropy':\r\n",
        "        val_loss = val_loss - (1/num_val)*math.log(y_hat_val[int(y_val[j])])\r\n",
        "      elif config.loss_func == 'mse':\r\n",
        "        val_loss = val_loss + (1/num_val)*(np.argmax(y_hat_val) - y_val[j])**2\r\n",
        "\r\n",
        "    accuracy = 100*count/num_train\r\n",
        "    val_accuracy = 100*count_val/num_val\r\n",
        "\r\n",
        "    print(\"     Loss\", loss)\r\n",
        "    print(\"     Accuracy\",accuracy)\r\n",
        "    print(\"     Validation Loss\", val_loss)\r\n",
        "    print(\"     Validation Accuracy\", val_accuracy)\r\n",
        "\r\n",
        "    metrics = {'epoch':i, 'val_accuracy': val_accuracy, 'val_loss': val_loss, 'accuracy': accuracy, 'loss': loss}\r\n",
        "    wandb.log(metrics)\r\n",
        "\r\n",
        "  y_hat_test, H_caches_test, A_caches_test = forward_propagation(X_test_flatten, Wb_matrix ,config.activation)\r\n",
        "  wandb.log({\"Confusion_Matrix\" : wandb.plot.confusion_matrix(\r\n",
        "                        probs=None,\r\n",
        "                        y_true=y_test,\r\n",
        "                        preds=np.argmax(y_hat_test, axis = 0),\r\n",
        "                        class_names=class_names)})\r\n",
        "  \r\n",
        "\r\n",
        "  wandb.run.finish()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "gnCQUIBAxxvy",
        "outputId": "ab09992e-5a4d-4080-d7f8-9795a162f806"
      },
      "source": [
        "mnist_swp()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkarthik21\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.22<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">zesty-terrain-90</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karthik21/cs6910-assignment01\" target=\"_blank\">https://wandb.ai/karthik21/cs6910-assignment01</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/karthik21/cs6910-assignment01/runs/30fstgb5\" target=\"_blank\">https://wandb.ai/karthik21/cs6910-assignment01/runs/30fstgb5</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210313_181152-30fstgb5</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "     Loss 0.316195736911371\n",
            "     Accuracy 90.37222222222222\n",
            "     Validation Loss 0.18549879108774947\n",
            "     Validation Accuracy 94.63333333333334\n",
            "Epoch: 2\n",
            "     Loss 0.1581142536184333\n",
            "     Accuracy 95.33333333333333\n",
            "     Validation Loss 0.1415988986262951\n",
            "     Validation Accuracy 95.85\n",
            "Epoch: 3\n",
            "     Loss 0.1237141681413657\n",
            "     Accuracy 96.34814814814816\n",
            "     Validation Loss 0.12483939227732765\n",
            "     Validation Accuracy 96.33333333333333\n",
            "Epoch: 4\n",
            "     Loss 0.10410452547801634\n",
            "     Accuracy 96.94814814814815\n",
            "     Validation Loss 0.11512925328921053\n",
            "     Validation Accuracy 96.45\n",
            "Epoch: 5\n",
            "     Loss 0.09013265717746005\n",
            "     Accuracy 97.40925925925926\n",
            "     Validation Loss 0.10770637660469148\n",
            "     Validation Accuracy 96.58333333333333\n",
            "Epoch: 6\n",
            "     Loss 0.07979201315613148\n",
            "     Accuracy 97.73333333333333\n",
            "     Validation Loss 0.10147077621831394\n",
            "     Validation Accuracy 96.71666666666667\n",
            "Epoch: 7\n",
            "     Loss 0.07164757708142257\n",
            "     Accuracy 97.9888888888889\n",
            "     Validation Loss 0.09849277421992504\n",
            "     Validation Accuracy 96.73333333333333\n",
            "Epoch: 8\n",
            "     Loss 0.06496225463502896\n",
            "     Accuracy 98.16851851851852\n",
            "     Validation Loss 0.09742241310669546\n",
            "     Validation Accuracy 96.75\n",
            "Epoch: 9\n",
            "     Loss 0.05952972355553977\n",
            "     Accuracy 98.31851851851852\n",
            "     Validation Loss 0.09462351189325292\n",
            "     Validation Accuracy 96.85\n",
            "Epoch: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXINphelC-9O"
      },
      "source": [
        ""
      ]
    }
  ]
}