{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6910_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodikarthik21/CS6910---Fundamentals-of-Deep-Learning/blob/main/Assignment01/CS6910_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRwBqsxQoczw"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ods22NlvpAfG"
      },
      "source": [
        "import wandb\r\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edFb4Fygf0hv"
      },
      "source": [
        "#Question 1 (2 Marks)\r\n",
        "Download the fashion-MNIST dataset and plot 1 sample image for each class as shown in the grid below. Use \"from keras.datasets import fashion_mnist\" for getting the fashion mnist dataset.\r\n",
        "\r\n",
        "ï»¿"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9ygxnE_ctp"
      },
      "source": [
        "from keras.datasets import fashion_mnist\r\n",
        "from matplotlib import pyplot\r\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "label = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "for i in range(10):\r\n",
        "   wandb.init(project=\"cs6910-assignment01\")\r\n",
        "   wandb.run.name = \"Q1_run_{}\".format(i+1)\r\n",
        "   for j in range(30):\r\n",
        "     if y_train[j] == i:\r\n",
        "       wandb.log({\"examples\": [wandb.Image(X_train[j], caption=label[i])]})\r\n",
        "       break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DMgxgi4PRGt"
      },
      "source": [
        "# Question 2 (10 Marks)\r\n",
        "\r\n",
        "Implement a feedforward neural network which takes images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes.\r\n",
        "\r\n",
        "Your code should be flexible so that it is easy to change the number of hidden layers and the number of neurons in each hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3thNIX-cOIA3"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def sigmoid(z):\r\n",
        "  g = 1/(1+np.exp(-z))\r\n",
        "  return g\r\n",
        "\r\n",
        "def tanh(z):\r\n",
        "  g = np.tanh(z)\r\n",
        "  return g\r\n",
        "\r\n",
        "def relu(z):\r\n",
        "  return np.maximum(0,z)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_qU08dQy3f5"
      },
      "source": [
        "def softmax(x):\r\n",
        "  return np.exp(x)/np.sum(np.exp(x), axis = 0)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXeouW-aXGsb"
      },
      "source": [
        "def initialize(initializer, size1, size2):\r\n",
        "  if(initializer == \"random\"):\r\n",
        "     W = np.random.randn(size1, size2)\r\n",
        "     return W\r\n",
        "\r\n",
        "  if(initializer == \"Xavier\"):\r\n",
        "     W = np.random.randn(size1, size2) * np.sqrt(1/size2)\r\n",
        "     return W\r\n",
        "\r\n",
        "  print(\"Enter the name of initializer correctly\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6P2Su_1dv30"
      },
      "source": [
        "def linear_forward(A, W, b, activation):\r\n",
        "  Z = np.dot(W, A) + b \r\n",
        "  cache = (A, W, b)\r\n",
        "\r\n",
        "  return Z, cache"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7zsskSyU1ZO"
      },
      "source": [
        "def activation_forward(A_prev, W, b, activation):\r\n",
        "  Z, linear_cache = linear_forward(A_prev, W, b)\r\n",
        "  activation_cache = Z \r\n",
        "  if activation == 'relu':\r\n",
        "    A = relu(Z)\r\n",
        "  elif activation == 'sigmoid':\r\n",
        "    A = sigmoid(Z)\r\n",
        "  elif activation =='tanh':\r\n",
        "    A = tanh(Z)\r\n",
        "  elif activation == 'softmax':\r\n",
        "    A = softmax(Z)\r\n",
        "  return A, activation_cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zXc1-js-dgL"
      },
      "source": [
        "def initialize_Wb_matrix(layer_dims, initializer):\r\n",
        "        \r\n",
        "    np.random.seed(3)\r\n",
        "    Wb_matrix = {}\r\n",
        "    L = len(layer_dims)            # number of layers in the network\r\n",
        "\r\n",
        "    for l in range(1, L):\r\n",
        "        Wb_matrix['W' + str(l)] = initializer(layer_dims[l], layer_dims[l-1])\r\n",
        "        Wb_matrix['b' + str(l)] = np.zeros((layer_dims[l], 1))\r\n",
        "    \r\n",
        "    return Wb_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DITldZOSHNt2"
      },
      "source": [
        "def L_layer_model(X, Wb_matrix, activation):\r\n",
        "    A = X\r\n",
        "    L = len(Wb_matrix) // 2\r\n",
        "    caches = []\r\n",
        "\r\n",
        "    for l in range(1, L):\r\n",
        "        A_prev = A \r\n",
        "        A, cache = activation_forward(A_prev, Wb_matrix['W{:d}'.format(l)], Wb_matrix['b{:d}'.format(l)], activation)\r\n",
        "        caches.append(cache)\r\n",
        "\r\n",
        "    AL, cache = activation_forward(A, Wb_matrix['W%d' % L], Wb_matrix['b%d' % L], activation='softmax')\r\n",
        "    caches.append(cache)\r\n",
        "\r\n",
        "    return AL, caches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_rbLFKN4et"
      },
      "source": [
        "def forward_propagation(X, num_hidden, size_hidden, initializer, activation):\r\n",
        "\r\n",
        "  layer_dims = [X.shape(0)]\r\n",
        "  for l in range(1, num_hidden):\r\n",
        "    layer_dims.append(size_hidden)\r\n",
        "  layer_dims.append(10)\r\n",
        "  \r\n",
        "  Wb_matrix = initialize_Wb_matrix(layer_dims, initializer)\r\n",
        "  AL, caches = L_layer_model(X, Wb_matrix, activation)\r\n",
        "\r\n",
        "  return AL, caches"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXeoLIx6SVwB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}