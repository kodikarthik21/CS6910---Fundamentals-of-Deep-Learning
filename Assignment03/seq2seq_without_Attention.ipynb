{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_without_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodikarthik21/CS6910---Fundamentals-of-Deep-Learning/blob/main/Assignment03/seq2seq_without_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXMvklWP41yA",
        "outputId": "6005a5dd-c373-486c-f7da-575ef3793ebc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4BZBkwtYydm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0432790d-d8fc-4d15-d494-494e648f47a4"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/lexicons.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/lexicons.zip\n",
            "   creating: lexicons/\n",
            "  inflating: lexicons/ta.translit.sampled.test.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.dev.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.train.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-BjJkmtJfD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFeaNePLZuvV"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.train.tsv\", sep = '\\t', header = None)\n",
        "train_df = train_df.dropna(axis=0)\n",
        "\n",
        "val_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.dev.tsv\", sep = '\\t', header = None)\n",
        "val_df = val_df.dropna(axis=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-icrnCDBdyn8",
        "outputId": "4654be00-0eb3-4a0e-a1f5-805b3d670d8c"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>fiat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>phiyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>piyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>firaans</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>france</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68213</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>holtt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68214</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoold</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68215</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoolt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68216</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hooltt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68217</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hult</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68215 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0        1  2\n",
              "0         ஃபியட்     fiat  2\n",
              "1         ஃபியட்   phiyat  1\n",
              "2         ஃபியட்    piyat  1\n",
              "3      ஃபிரான்ஸ்  firaans  1\n",
              "4      ஃபிரான்ஸ்   france  2\n",
              "...          ...      ... ..\n",
              "68213     ஹோல்ட்    holtt  1\n",
              "68214     ஹோல்ட்    hoold  1\n",
              "68215     ஹோல்ட்    hoolt  1\n",
              "68216     ஹோல்ட்   hooltt  1\n",
              "68217     ஹோல்ட்     hult  1\n",
              "\n",
              "[68215 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "D_sUDPUSXsc2",
        "outputId": "da663d8b-f0ea-44eb-b0b1-938551011c1a"
      },
      "source": [
        "val_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>fire</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>phayar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>baar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>far</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6822</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolley</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6823</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolli</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6824</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6825</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hooly</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6826</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>huli</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6827 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0        1  2\n",
              "0     ஃபயர்     fire  3\n",
              "1     ஃபயர்   phayar  1\n",
              "2     ஃபார்     baar  1\n",
              "3     ஃபார்      bar  1\n",
              "4     ஃபார்      far  1\n",
              "...     ...      ... ..\n",
              "6822   ஹோலி  hoolley  1\n",
              "6823   ஹோலி   hoolli  2\n",
              "6824   ஹோலி   hoolly  1\n",
              "6825   ஹோலி    hooly  2\n",
              "6826   ஹோலி     huli  1\n",
              "\n",
              "[6827 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xenfuPMts4c",
        "outputId": "94a8f027-46ee-4443-bfbc-7760ff59d13d"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for input_text,target_text in zip(train_df[1][0:],train_df[0][0:]):\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "if ' ' not in input_token_index:\n",
        "  input_token_index[' '] = len(input_token_index)\n",
        "\n",
        "if ' ' not in target_token_index:\n",
        "  target_token_index[' '] = len(target_token_index)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters) + 1\n",
        "num_decoder_tokens = len(target_characters) + 1\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68215\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 47\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6AJbTIUY895"
      },
      "source": [
        "# Vectorize the data.\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for val_input_text,val_target_text in zip(val_df[1][0:],val_df[0][0:]):\n",
        "    val_input_texts.append(val_input_text)\n",
        "    val_target_texts.append(val_target_text)\n",
        "\n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(val_input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(val_target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8iqmjxcw9v9"
      },
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 32\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "embedding = keras.layers.Embedding(num_encoder_tokens, embedding_size, name=\"embedding_1\")(encoder_inputs)\n",
        "encoder_seq, *encoder_state = keras.layers.LSTM(hidden_size, return_sequences=True,return_state = True, name=\"encoder_1\") (embedding)\n",
        "encoder_seq, *encoder_state = keras.layers.LSTM(hidden_size, return_sequences=True,return_state = True, name=\"encoder_2\") (encoder_seq)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None,), name=\"input_2\")\n",
        "decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size, name=\"embedding_2\")(decoder_inputs)\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_seq, *_ = keras.layers.LSTM(hidden_size,return_sequences=True, return_state=True, name=\"decoder_1\")(decoder_embedding,initial_state=encoder_state)\n",
        "decoder_seq, *_ = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True, name=\"decoder_2\") (decoder_seq)\n",
        "\n",
        "decoder_outputs = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\", name=\"dense_1\")(decoder_seq)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u82k-7SHxHbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be0c9b2-d02c-422e-d2c4-6e433f1b3911"
      },
      "source": [
        "batch_size = 512  # Batch size for training.\n",
        "epochs = 10 # Number of epochs to train for.\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=([encoder_input_data, decoder_input_data],\n",
        "                    decoder_target_data)\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 48s 102ms/step - loss: 2.2639 - accuracy: 0.6741 - val_loss: 1.1099 - val_accuracy: 0.7194\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 12s 90ms/step - loss: 1.0820 - accuracy: 0.7231 - val_loss: 1.0084 - val_accuracy: 0.7363\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 12s 89ms/step - loss: 0.9834 - accuracy: 0.7464 - val_loss: 0.9077 - val_accuracy: 0.7624\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 12s 90ms/step - loss: 0.8907 - accuracy: 0.7644 - val_loss: 0.8525 - val_accuracy: 0.7700\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 12s 90ms/step - loss: 0.8454 - accuracy: 0.7722 - val_loss: 0.8217 - val_accuracy: 0.7768\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 12s 90ms/step - loss: 0.8172 - accuracy: 0.7769 - val_loss: 0.8017 - val_accuracy: 0.7778\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 12s 91ms/step - loss: 0.7925 - accuracy: 0.7799 - val_loss: 0.7817 - val_accuracy: 0.7818\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 12s 91ms/step - loss: 0.7770 - accuracy: 0.7821 - val_loss: 0.7654 - val_accuracy: 0.7838\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 12s 89ms/step - loss: 0.7622 - accuracy: 0.7858 - val_loss: 0.7541 - val_accuracy: 0.7895\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 12s 89ms/step - loss: 0.7518 - accuracy: 0.7908 - val_loss: 0.7437 - val_accuracy: 0.7955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_21_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrIp8f72Kj8f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}