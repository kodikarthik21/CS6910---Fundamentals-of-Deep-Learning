{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Copy of seq2seq_without_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodikarthik21/CS6910---Fundamentals-of-Deep-Learning/blob/main/Assignment03/seq2seq_without_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXMvklWP41yA",
        "outputId": "e72d7e70-7caa-46d6-9115-8bee0097f8f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4BZBkwtYydm",
        "outputId": "63868bf3-caa6-4ef9-c3ed-0068cda5f274"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/lexicons.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/lexicons.zip\n",
            "   creating: lexicons/\n",
            "  inflating: lexicons/ta.translit.sampled.test.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.dev.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.train.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqn-Ah4BVhLP",
        "outputId": "ccc57cb2-3b90-49f6-c00d-def051e3fedb"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 18.8MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.2MB/s \n",
            "\u001b[?25hCollecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.9MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=0d3acbdd345c6f39ef61283708a05f968fdd1ecd3c204293473ff309fff620a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=8b4e695015cbd777346c53ba2b61b18808c9919ce1fe6ba6ecf48e0b000c300d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: shortuuid, docker-pycreds, sentry-sdk, subprocess32, configparser, smmap, gitdb, GitPython, pathtools, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ2dlNYDASNE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7d0db52c-a8a1-493e-eb26-d2a2b11a77bd"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-BjJkmtJfD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFeaNePLZuvV"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.train.tsv\", sep = '\\t', header = None)\n",
        "train_df = train_df.dropna(axis=0)\n",
        "\n",
        "val_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.dev.tsv\", sep = '\\t', header = None)\n",
        "val_df = val_df.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icrnCDBdyn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "fdc99769-5fff-43ec-87a3-ddb1027fedce"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>fiat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>phiyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>piyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>firaans</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>france</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68213</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>holtt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68214</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoold</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68215</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoolt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68216</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hooltt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68217</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hult</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68215 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0        1  2\n",
              "0         ஃபியட்     fiat  2\n",
              "1         ஃபியட்   phiyat  1\n",
              "2         ஃபியட்    piyat  1\n",
              "3      ஃபிரான்ஸ்  firaans  1\n",
              "4      ஃபிரான்ஸ்   france  2\n",
              "...          ...      ... ..\n",
              "68213     ஹோல்ட்    holtt  1\n",
              "68214     ஹோல்ட்    hoold  1\n",
              "68215     ஹோல்ட்    hoolt  1\n",
              "68216     ஹோல்ட்   hooltt  1\n",
              "68217     ஹோல்ட்     hult  1\n",
              "\n",
              "[68215 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sUDPUSXsc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "f628fa77-21e1-4b56-ef98-529d926a3107"
      },
      "source": [
        "val_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>fire</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>phayar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>baar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>far</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6822</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolley</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6823</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolli</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6824</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6825</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hooly</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6826</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>huli</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6827 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0        1  2\n",
              "0     ஃபயர்     fire  3\n",
              "1     ஃபயர்   phayar  1\n",
              "2     ஃபார்     baar  1\n",
              "3     ஃபார்      bar  1\n",
              "4     ஃபார்      far  1\n",
              "...     ...      ... ..\n",
              "6822   ஹோலி  hoolley  1\n",
              "6823   ஹோலி   hoolli  2\n",
              "6824   ஹோலி   hoolly  1\n",
              "6825   ஹோலி    hooly  2\n",
              "6826   ஹோலி     huli  1\n",
              "\n",
              "[6827 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xenfuPMts4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36853b98-6b9d-486b-e09f-8148ab37cdf4"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for input_text,target_text in zip(train_df[1][0:],train_df[0][0:]):\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "if ' ' not in input_token_index:\n",
        "  input_token_index[' '] = len(input_token_index)\n",
        "\n",
        "if ' ' not in target_token_index:\n",
        "  target_token_index[' '] = len(target_token_index)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters) + 1\n",
        "num_decoder_tokens = len(target_characters) + 1\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68215\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 47\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6AJbTIUY895"
      },
      "source": [
        "# Vectorize the data.\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for val_input_text,val_target_text in zip(val_df[1][0:],val_df[0][0:]):\n",
        "    val_input_texts.append(val_input_text)\n",
        "    val_target_texts.append(val_target_text)\n",
        "\n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    val_encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7syg0ppVMhAl"
      },
      "source": [
        "def model(cell_name, embedding_size, hidden_size, num_enc_layers, num_dec_layers, dropout, r_dropout, batch_size, num_epochs, optimizer):\n",
        "  \n",
        "  cell_type = { \"RNN\": keras.layers.SimpleRNN,\n",
        "                \"GRU\": keras.layers.GRU,\n",
        "                \"LSTM\": keras.layers.LSTM\n",
        "  }\n",
        "\n",
        "  learning_rate = 0.01\n",
        "  decay_rate = 0\n",
        "\n",
        "  optimizers = {\"adam\": tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_rate),\n",
        "                \"nadam\": tf.keras.optimizers.Nadam(lr=learning_rate, decay=decay_rate),\n",
        "                \"rmsprop\": tf.keras.optimizers.RMSprop(lr=learning_rate, decay=decay_rate),\n",
        "                \"adagrad\": tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
        "  }\n",
        "\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "  embedding = keras.layers.Embedding(num_encoder_tokens, embedding_size, name=\"embedding_1\")(encoder_inputs)\n",
        "  encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_1\") (embedding)\n",
        "  for i in range(1, num_enc_layers):\n",
        "    encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_\"+str(i+1), dropout=dropout,\n",
        "                                                       recurrent_dropout=r_dropout) (encoder_seq)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = keras.Input(shape=(None,), name=\"input_2\")\n",
        "  decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size, name=\"embedding_2\")(decoder_inputs)\n",
        "\n",
        "  # We set up our decoder to return full output sequences,\n",
        "  # and to return internal states as well. We don't use the\n",
        "  # return states in the training model, but we will use them in inference.\n",
        "  decoder_seq, *_ = cell_type[cell_name](hidden_size,return_sequences=True, return_state=True, name=\"decoder_1\")(decoder_embedding,initial_state=encoder_state)\n",
        "  for i in range(1, num_dec_layers):\n",
        "    decoder_seq, *_ = cell_type[cell_name](hidden_size, return_sequences=True, return_state=True, name=\"decoder_\"+str(i+1),dropout=dropout,\n",
        "                                      recurrent_dropout=r_dropout) (decoder_seq)\n",
        "\n",
        "  decoder_outputs = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\", name=\"dense_1\")(decoder_seq)\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers[optimizer], loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  model.fit(\n",
        "      [encoder_input_data, decoder_input_data],\n",
        "      decoder_target_data,\n",
        "      batch_size=batch_size,\n",
        "      epochs=num_epochs,\n",
        "      validation_data=([val_encoder_input_data, val_decoder_input_data],\n",
        "                      val_decoder_target_data),\n",
        "      callbacks=[WandbCallback()]\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb30jmpVS4ga"
      },
      "source": [
        "def swp():\n",
        "\n",
        "  hyperparameter_defaults = dict(\n",
        "      cell_name = \"LSTM\",\n",
        "      embedding_size = 256,\n",
        "      hidden_size = 32,\n",
        "      num_enc_layers = 2,\n",
        "      num_dec_layers = 2,\n",
        "      dropout = 0.2,\n",
        "      r_dropout = 0.2,\n",
        "      batch_size = 512,\n",
        "      num_epochs = 10,\n",
        "      optimizer = \"adam\"\n",
        "  )\n",
        "\n",
        "  wandb.init(project=\"Assignment 3 without Attention\", config=hyperparameter_defaults)\n",
        "  config = wandb.config\n",
        "  wandb.run.name = \"{}_cell_{}_embSize_{}_hiddenSize_{}_encLayers_{}_decLayers_{}_dropout_{}_rDropout_{}_batchSize_{}_epochs_{}_opt\".format(config.cell_name, \n",
        "                    config.embedding_size,config.hidden_size, config.num_enc_layers, config.num_dec_layers, config.dropout, config.r_dropout, config.batch_size, config.num_epochs, \n",
        "                    config.optimizer)\n",
        "  \n",
        "  model(config.cell_name, config.embedding_size,config.hidden_size, config.num_enc_layers, config.num_dec_layers, config.dropout, config.r_dropout, config.batch_size, \n",
        "         config.num_epochs, config.optimizer)\n",
        "  wandb.run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad61A5fFV8qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f238ce61-a3b0-48e1-aba2-c7e3b3c19942"
      },
      "source": [
        "sweep_config = {\n",
        "  \"name\": \"My Sweep\",\n",
        "  \"method\": \"random\",\n",
        "  \"project\": \"Assignment02\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"cell_name\": {\n",
        "            \"values\": ['RNN', 'LSTM', 'GRU']\n",
        "        },\n",
        "        \"embedding_size\": {\n",
        "            \"values\":[16, 32, 64, 128, 256]\n",
        "        }, \n",
        "        \"hidden_size\": {\n",
        "            \"values\":[16, 32, 64, 128, 256]\n",
        "        },\n",
        "        \"num_enc_layers\":{\n",
        "            \"values\":[1, 2, 3]\n",
        "        },\n",
        "        \"num_dec_layers\":{\n",
        "            \"values\":[1, 2, 3]\n",
        "        },  \n",
        "        \"dropout\":{\n",
        "            \"values\":[0, 0.2, 0.3, 0.4]\n",
        "        },\n",
        "        \"r_dropout\": {\n",
        "            \"values\":[0, 0.2, 0.3, 0.4]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\":[256, 512]\n",
        "        },\n",
        "        \"num_epochs\": {\n",
        "            \"values\":[5, 10, 15]\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\":['adam', 'nadam','rmsprop','adagrad']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: kgj7mc2s\n",
            "Sweep URL: https://wandb.ai/kodikarthik21/uncategorized/sweeps/kgj7mc2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTRZta3d9NCM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "6d1251ff-274d-45ab-bfc1-71273584956a"
      },
      "source": [
        "wandb.agent('xsvxwp4i', swp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cvu6b6xw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_name: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dec_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_enc_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adagrad\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tr_dropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.28<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">olive-sweep-16</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/kodikarthik21/uncategorized\" target=\"_blank\">https://wandb.ai/kodikarthik21/uncategorized</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/kodikarthik21/uncategorized/sweeps/xsvxwp4i\" target=\"_blank\">https://wandb.ai/kodikarthik21/uncategorized/sweeps/xsvxwp4i</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/kodikarthik21/uncategorized/runs/cvu6b6xw\" target=\"_blank\">https://wandb.ai/kodikarthik21/uncategorized/runs/cvu6b6xw</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210504_041301-cvu6b6xw</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "134/134 [==============================] - 31s 201ms/step - loss: 2.1083 - accuracy: 0.5760 - val_loss: 1.1867 - val_accuracy: 0.7280\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 26s 192ms/step - loss: 1.2985 - accuracy: 0.7051 - val_loss: 1.0541 - val_accuracy: 0.7461\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 26s 191ms/step - loss: 1.1718 - accuracy: 0.7195 - val_loss: 0.9916 - val_accuracy: 0.7516\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 26s 191ms/step - loss: 1.1013 - accuracy: 0.7256 - val_loss: 0.9482 - val_accuracy: 0.7532\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 26s 190ms/step - loss: 1.0603 - accuracy: 0.7284 - val_loss: 0.9430 - val_accuracy: 0.7537\n",
            "Epoch 6/10\n",
            " 11/134 [=>............................] - ETA: 24s - loss: 1.0348 - accuracy: 0.7309"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2t-P6Ms9dZG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}