{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_without_Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodikarthik21/CS6910---Fundamentals-of-Deep-Learning/blob/main/Assignment03/seq2seq_without_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXMvklWP41yA",
        "outputId": "8231b90d-921b-4ac8-b138-83cb2688a4b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4BZBkwtYydm",
        "outputId": "05aa3b55-3f98-4397-c79c-bdd3b0274a36"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/lexicons.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/lexicons.zip\n",
            "   creating: lexicons/\n",
            "  inflating: lexicons/ta.translit.sampled.test.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.dev.tsv  \n",
            "  inflating: lexicons/ta.translit.sampled.train.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqn-Ah4BVhLP",
        "outputId": "47950cbf-6b78-4e7a-bbcb-ee961d70e38b"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=9773f305de558708b1207e51d2786e61c9a8a569c12313328b54f180ed6991b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=7d59fb3ef938b8c7a4149f9779339f9de8d611721f3f7c9ebf4b84e7e6c99e9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: sentry-sdk, subprocess32, pathtools, configparser, smmap, gitdb, GitPython, shortuuid, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ2dlNYDASNE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "ca24a6be-b929-4af4-c127-9f24084869bb"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-BjJkmtJfD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFeaNePLZuvV"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.train.tsv\", sep = '\\t', header = None)\n",
        "train_df = train_df.dropna(axis=0)\n",
        "\n",
        "val_df = pd.read_csv(\"/content/lexicons/ta.translit.sampled.dev.tsv\", sep = '\\t', header = None)\n",
        "val_df = val_df.dropna(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-icrnCDBdyn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "5220fa8c-eb47-492c-bcc3-485cf09d6bf6"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>fiat</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>phiyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபியட்</td>\n",
              "      <td>piyat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>firaans</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபிரான்ஸ்</td>\n",
              "      <td>france</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68213</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>holtt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68214</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoold</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68215</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hoolt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68216</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hooltt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68217</th>\n",
              "      <td>ஹோல்ட்</td>\n",
              "      <td>hult</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68215 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0        1  2\n",
              "0         ஃபியட்     fiat  2\n",
              "1         ஃபியட்   phiyat  1\n",
              "2         ஃபியட்    piyat  1\n",
              "3      ஃபிரான்ஸ்  firaans  1\n",
              "4      ஃபிரான்ஸ்   france  2\n",
              "...          ...      ... ..\n",
              "68213     ஹோல்ட்    holtt  1\n",
              "68214     ஹோல்ட்    hoold  1\n",
              "68215     ஹோல்ட்    hoolt  1\n",
              "68216     ஹோல்ட்   hooltt  1\n",
              "68217     ஹோல்ட்     hult  1\n",
              "\n",
              "[68215 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_sUDPUSXsc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "dfec6875-5083-4f37-dbd5-810d51fa288b"
      },
      "source": [
        "val_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>fire</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ஃபயர்</td>\n",
              "      <td>phayar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>baar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>bar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ஃபார்</td>\n",
              "      <td>far</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6822</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolley</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6823</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolli</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6824</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hoolly</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6825</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>hooly</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6826</th>\n",
              "      <td>ஹோலி</td>\n",
              "      <td>huli</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6827 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0        1  2\n",
              "0     ஃபயர்     fire  3\n",
              "1     ஃபயர்   phayar  1\n",
              "2     ஃபார்     baar  1\n",
              "3     ஃபார்      bar  1\n",
              "4     ஃபார்      far  1\n",
              "...     ...      ... ..\n",
              "6822   ஹோலி  hoolley  1\n",
              "6823   ஹோலி   hoolli  2\n",
              "6824   ஹோலி   hoolly  1\n",
              "6825   ஹோலி    hooly  2\n",
              "6826   ஹோலி     huli  1\n",
              "\n",
              "[6827 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xenfuPMts4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916f88bc-5995-480b-ff88-fac6aeb7ab46"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for input_text,target_text in zip(train_df[1][0:],train_df[0][0:]):\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "if ' ' not in input_token_index:\n",
        "  input_token_index[' '] = len(input_token_index)\n",
        "\n",
        "if ' ' not in target_token_index:\n",
        "  target_token_index[' '] = len(target_token_index)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters) + 1\n",
        "num_decoder_tokens = len(target_characters) + 1\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 68215\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 47\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6AJbTIUY895"
      },
      "source": [
        "# Vectorize the data.\n",
        "val_input_texts = []\n",
        "val_target_texts = []\n",
        "\n",
        "for val_input_text,val_target_text in zip(val_df[1][0:],val_df[0][0:]):\n",
        "    val_input_texts.append(val_input_text)\n",
        "    val_target_texts.append(val_target_text)\n",
        "\n",
        "val_encoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_encoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_input_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length), dtype=\"float32\"\n",
        ")\n",
        "val_decoder_target_data = np.zeros(\n",
        "    (len(val_input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(val_input_texts, val_target_texts)):\n",
        "    for t, char in enumerate(val_input_text):\n",
        "        val_encoder_input_data[i, t] = input_token_index[char]\n",
        "    encoder_input_data[i, t + 1 :] = input_token_index[\" \"]\n",
        "    for t, char in enumerate(val_target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t] = target_token_index[char]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :] = target_token_index[\" \"]\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7syg0ppVMhAl"
      },
      "source": [
        "def model(cell_name, embedding_size, hidden_size, num_enc_layers, num_dec_layers, dropout, r_dropout, batch_size, num_epochs, optimizer):\n",
        "  \n",
        "  cell_type = { \"RNN\": keras.layers.SimpleRNN,\n",
        "                \"GRU\": keras.layers.GRU,\n",
        "                \"LSTM\": keras.layers.LSTM\n",
        "  }\n",
        "\n",
        "  learning_rate = 1e-3\n",
        "  decay_rate = learning_rate / num_epochs\n",
        "\n",
        "  optimizers = {\"adam\": tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_rate),\n",
        "                \"nadam\": tf.keras.optimizers.Nadam(lr=learning_rate, decay=decay_rate),\n",
        "                \"rmsprop\": tf.keras.optimizers.RMSprop(lr=learning_rate, decay=decay_rate),\n",
        "                \"adagrad\": tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
        "  }\n",
        "\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "  embedding = keras.layers.Embedding(num_encoder_tokens, embedding_size, name=\"embedding_1\")(encoder_inputs)\n",
        "  encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_1\") (embedding)\n",
        "  for i in range(1, num_enc_layers):\n",
        "    encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_\"+str(i+1), dropout=dropout,\n",
        "                                                       recurrent_dropout=r_dropout) (encoder_seq)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = keras.Input(shape=(None,), name=\"input_2\")\n",
        "  decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size, name=\"embedding_2\")(decoder_inputs)\n",
        "\n",
        "  # We set up our decoder to return full output sequences,\n",
        "  # and to return internal states as well. We don't use the\n",
        "  # return states in the training model, but we will use them in inference.\n",
        "  decoder_seq, *_ = cell_type[cell_name](hidden_size,return_sequences=True, return_state=True, name=\"decoder_1\")(decoder_embedding,initial_state=encoder_state)\n",
        "  for i in range(1, num_dec_layers):\n",
        "    decoder_seq, *_ = cell_type[cell_name](hidden_size, return_sequences=True, return_state=True, name=\"decoder_\"+str(i+1),dropout=dropout,\n",
        "                                      recurrent_dropout=r_dropout) (decoder_seq)\n",
        "\n",
        "  decoder_outputs = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\", name=\"dense_1\")(decoder_seq)\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers[optimizer], loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  model.fit(\n",
        "      [encoder_input_data, decoder_input_data],\n",
        "      decoder_target_data,\n",
        "      batch_size=batch_size,\n",
        "      epochs=num_epochs,\n",
        "      validation_data=([encoder_input_data, decoder_input_data],\n",
        "                      decoder_target_data),\n",
        "      callbacks=[WandbCallback()]\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb30jmpVS4ga"
      },
      "source": [
        "def swp():\n",
        "\n",
        "  hyperparameter_defaults = dict(\n",
        "      cell_name = \"LSTM\",\n",
        "      embedding_size = 256,\n",
        "      hidden_size = 32,\n",
        "      num_enc_layers = 2,\n",
        "      num_dec_layers = 2,\n",
        "      dropout = 0.2,\n",
        "      r_dropout = 0.2,\n",
        "      batch_size = 512,\n",
        "      num_epochs = 10,\n",
        "      optimizer = \"adam\"\n",
        "  )\n",
        "\n",
        "  wandb.init(project=\"Assignment 3 without Attention\", config=hyperparameter_defaults)\n",
        "  config = wandb.config\n",
        "  wandb.run.name = \"{}_cell_{}_embSize_{}_hiddenSize_{}_encLayers_{}_decLayers_{}_dropout_{}_rDropout_{}_batchSize_{}_epochs_{}_opt\".format(config.cell_name, \n",
        "                    config.embedding_size,config.hidden_size, config.num_enc_layers, config.num_dec_layers, config.dropout, config.r_dropout, config.batch_size, config.num_epochs, \n",
        "                    config.optimizer)\n",
        "  \n",
        "  model(config.cell_name, config.embedding_size,config.hidden_size, config.num_enc_layers, config.num_dec_layers, config.dropout, config.r_dropout, config.batch_size, \n",
        "         config.num_epochs, config.optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad61A5fFV8qE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3435bc-108c-4785-c0f9-6a8a5bb2bc29"
      },
      "source": [
        "sweep_config = {\n",
        "  \"name\": \"My Sweep\",\n",
        "  \"method\": \"random\",\n",
        "  \"project\": \"Assignment02\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"cell_name\": {\n",
        "            \"values\": ['RNN', 'LSTM', 'GRU']\n",
        "        },\n",
        "        \"embedding_size\": {\n",
        "            \"values\":[16, 32, 64, 128, 256]\n",
        "        }, \n",
        "        \"hidden_size\": {\n",
        "            \"values\":[16, 32, 64, 128, 256]\n",
        "        },\n",
        "        \"num_enc_layers\":{\n",
        "            \"values\":[1, 2, 3]\n",
        "        },\n",
        "        \"num_dec_layers\":{\n",
        "            \"values\":[1, 2, 3]\n",
        "        },  \n",
        "        \"dropout\":{\n",
        "            \"values\":[0, 0.2, 0.3, 0.4]\n",
        "        },\n",
        "        \"r_dropout\": {\n",
        "            \"values\":[0, 0.2, 0.3, 0.4]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\":[256, 512, 1024]\n",
        "        },\n",
        "        \"num_epochs\": {\n",
        "            \"values\":[5, 10, 15]\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\":['adam', 'nadam','rmsprop','adagrad']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: do6etd4d\n",
            "Sweep URL: https://wandb.ai/kodikarthik21/uncategorized/sweeps/do6etd4d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTRZta3d9NCM"
      },
      "source": [
        "#wandb.agent('fxc8lkyg', swp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB3tLYEIO6Kc"
      },
      "source": [
        "def model_without_wandb(cell_name, embedding_size, hidden_size, num_enc_layers, num_dec_layers, dropout, r_dropout, batch_size, num_epochs, optimizer):\n",
        "  \n",
        "  cell_type = { \"RNN\": keras.layers.SimpleRNN,\n",
        "                \"GRU\": keras.layers.GRU,\n",
        "                \"LSTM\": keras.layers.LSTM\n",
        "  }\n",
        "\n",
        "  learning_rate = 1e-3\n",
        "  decay_rate = learning_rate / num_epochs\n",
        "\n",
        "  optimizers = {\"adam\": tf.keras.optimizers.Adam(lr=learning_rate, decay=decay_rate),\n",
        "                \"nadam\": tf.keras.optimizers.Nadam(lr=learning_rate, decay=decay_rate),\n",
        "                \"rmsprop\": tf.keras.optimizers.RMSprop(lr=learning_rate, decay=decay_rate),\n",
        "                \"adagrad\": tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
        "  }\n",
        "\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = keras.layers.Input(shape=(None,), name=\"input_1\")\n",
        "  embedding = keras.layers.Embedding(num_encoder_tokens, embedding_size, name=\"embedding_1\")(encoder_inputs)\n",
        "  encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_1\") (embedding)\n",
        "  for i in range(1, num_enc_layers):\n",
        "    encoder_seq, *encoder_state = cell_type[cell_name](hidden_size, return_sequences=True,return_state = True, name=\"encoder_\"+str(i+1), dropout=dropout,\n",
        "                                                       recurrent_dropout=r_dropout) (encoder_seq)\n",
        "\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = keras.Input(shape=(None,), name=\"input_2\")\n",
        "  decoder_embedding = keras.layers.Embedding(num_decoder_tokens, embedding_size, name=\"embedding_2\")(decoder_inputs)\n",
        "\n",
        "  # We set up our decoder to return full output sequences,\n",
        "  # and to return internal states as well. We don't use the\n",
        "  # return states in the training model, but we will use them in inference.\n",
        "  decoder_seq, *_ = cell_type[cell_name](hidden_size,return_sequences=True, return_state=True, name=\"decoder_1\")(decoder_embedding,initial_state=encoder_state)\n",
        "  for i in range(1, num_dec_layers):\n",
        "    decoder_seq, *_ = cell_type[cell_name](hidden_size, return_sequences=True, return_state=True, name=\"decoder_\"+str(i+1),dropout=dropout,\n",
        "                                      recurrent_dropout=r_dropout) (decoder_seq)\n",
        "\n",
        "  decoder_outputs = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\", name=\"dense_1\")(decoder_seq)\n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizers[optimizer], loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "  )\n",
        "  model.fit(\n",
        "      [encoder_input_data, decoder_input_data],\n",
        "      decoder_target_data,\n",
        "      batch_size=batch_size,\n",
        "      epochs=num_epochs,\n",
        "      validation_data=([encoder_input_data, decoder_input_data],\n",
        "                      decoder_target_data)\n",
        "  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkdNvZWrPIuB",
        "outputId": "a2dd5841-0b38-430d-8338-28ab6b70e7ca"
      },
      "source": [
        "model_without_wandb(\"LSTM\", 256, 256, 2, 2, 0.3, 0, 256, 15, \"adam\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "267/267 [==============================] - 52s 61ms/step - loss: 1.3203 - accuracy: 0.7062 - val_loss: 0.8467 - val_accuracy: 0.7704\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.8127 - accuracy: 0.7756 - val_loss: 0.7599 - val_accuracy: 0.7901\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.7453 - accuracy: 0.7969 - val_loss: 0.6850 - val_accuracy: 0.8172\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 15s 57ms/step - loss: 0.6806 - accuracy: 0.8196 - val_loss: 0.6300 - val_accuracy: 0.8381\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.6342 - accuracy: 0.8390 - val_loss: 0.5666 - val_accuracy: 0.8639\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.5764 - accuracy: 0.8628 - val_loss: 0.5088 - val_accuracy: 0.8916\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.5132 - accuracy: 0.8897 - val_loss: 0.4524 - val_accuracy: 0.9181\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.4713 - accuracy: 0.9132 - val_loss: 0.4407 - val_accuracy: 0.9347\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.4748 - accuracy: 0.9277 - val_loss: 0.4491 - val_accuracy: 0.9436\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.4878 - accuracy: 0.9372 - val_loss: 0.4779 - val_accuracy: 0.9492\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.5132 - accuracy: 0.9417 - val_loss: 0.5107 - val_accuracy: 0.9535\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.5522 - accuracy: 0.9464 - val_loss: 0.5590 - val_accuracy: 0.9551\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.5824 - accuracy: 0.9499 - val_loss: 0.5990 - val_accuracy: 0.9584\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 15s 57ms/step - loss: 0.6253 - accuracy: 0.9515 - val_loss: 0.6491 - val_accuracy: 0.9599\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 15s 56ms/step - loss: 0.6809 - accuracy: 0.9535 - val_loss: 0.6959 - val_accuracy: 0.9616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DForTbvLP6Rp",
        "outputId": "b0629294-9aa9-4615-efb2-5987f05c75a7"
      },
      "source": [
        "model_without_wandb(\"LSTM\", 256, 256, 2, 1, 0.4, 0.2, 256, 15, \"nadam\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/15\n",
            "267/267 [==============================] - 45s 151ms/step - loss: 1.2304 - accuracy: 0.7203 - val_loss: 0.7790 - val_accuracy: 0.7837\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 40s 148ms/step - loss: 0.7612 - accuracy: 0.7910 - val_loss: 0.6738 - val_accuracy: 0.8177\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.6595 - accuracy: 0.8218 - val_loss: 0.5896 - val_accuracy: 0.8443\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.5492 - accuracy: 0.8568 - val_loss: 0.4539 - val_accuracy: 0.8913\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 39s 148ms/step - loss: 0.4499 - accuracy: 0.8945 - val_loss: 0.3874 - val_accuracy: 0.9179\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 40s 150ms/step - loss: 0.3853 - accuracy: 0.9201 - val_loss: 0.3538 - val_accuracy: 0.9363\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 40s 149ms/step - loss: 0.3528 - accuracy: 0.9381 - val_loss: 0.3432 - val_accuracy: 0.9476\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.3562 - accuracy: 0.9461 - val_loss: 0.3598 - val_accuracy: 0.9515\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 39s 148ms/step - loss: 0.3655 - accuracy: 0.9519 - val_loss: 0.3740 - val_accuracy: 0.9565\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.3898 - accuracy: 0.9558 - val_loss: 0.3960 - val_accuracy: 0.9600\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.4078 - accuracy: 0.9587 - val_loss: 0.4250 - val_accuracy: 0.9628\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 40s 148ms/step - loss: 0.4467 - accuracy: 0.9606 - val_loss: 0.4634 - val_accuracy: 0.9640\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 39s 146ms/step - loss: 0.4714 - accuracy: 0.9624 - val_loss: 0.7153 - val_accuracy: 0.9110\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 39s 147ms/step - loss: 0.6088 - accuracy: 0.9406 - val_loss: 0.5663 - val_accuracy: 0.9621\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 39s 146ms/step - loss: 0.5739 - accuracy: 0.9613 - val_loss: 0.6075 - val_accuracy: 0.9652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1uXZ1DXQLIE",
        "outputId": "d9d39f7e-24f7-4ec9-ea85-f7f2c6b9210b"
      },
      "source": [
        "model_without_wandb(\"LSTM\", 256, 256, 3, 1, 0, 0.2, 256, 15, \"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer encoder_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer encoder_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/15\n",
            "267/267 [==============================] - 66s 225ms/step - loss: 1.1567 - accuracy: 0.7236 - val_loss: 0.7588 - val_accuracy: 0.7923\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 58s 218ms/step - loss: 0.7242 - accuracy: 0.8062 - val_loss: 0.6496 - val_accuracy: 0.8357\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 58s 218ms/step - loss: 0.6503 - accuracy: 0.8398 - val_loss: 0.6205 - val_accuracy: 0.8615\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 58s 219ms/step - loss: 0.6095 - accuracy: 0.8694 - val_loss: 0.6081 - val_accuracy: 0.8895\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 59s 220ms/step - loss: 0.6190 - accuracy: 0.8948 - val_loss: 0.6351 - val_accuracy: 0.9097\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 59s 222ms/step - loss: 0.6438 - accuracy: 0.9151 - val_loss: 0.6585 - val_accuracy: 0.9318\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 59s 220ms/step - loss: 0.6864 - accuracy: 0.9309 - val_loss: 0.7306 - val_accuracy: 0.9377\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 59s 221ms/step - loss: 0.7295 - accuracy: 0.9419 - val_loss: 0.7840 - val_accuracy: 0.9493\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 58s 219ms/step - loss: 0.8009 - accuracy: 0.9485 - val_loss: 0.8593 - val_accuracy: 0.9537\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 58s 219ms/step - loss: 0.8881 - accuracy: 0.9539 - val_loss: 0.9477 - val_accuracy: 0.9550\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 58s 219ms/step - loss: 0.9785 - accuracy: 0.9576 - val_loss: 1.0199 - val_accuracy: 0.9603\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 58s 218ms/step - loss: 1.0483 - accuracy: 0.9611 - val_loss: 1.0892 - val_accuracy: 0.9645\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 58s 217ms/step - loss: 1.0777 - accuracy: 0.9641 - val_loss: 1.1687 - val_accuracy: 0.9661\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 57s 215ms/step - loss: 1.2159 - accuracy: 0.9652 - val_loss: 1.2454 - val_accuracy: 0.9674\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 57s 213ms/step - loss: 1.2716 - accuracy: 0.9670 - val_loss: 1.3262 - val_accuracy: 0.9683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfjaf3bYREAK",
        "outputId": "565c3986-560b-498d-96ec-7c38f73ba2f3"
      },
      "source": [
        "model_without_wandb(\"GRU\", 256, 256, 3, 3, 0, 0, 256, 15, \"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "267/267 [==============================] - 58s 74ms/step - loss: 1.1920 - accuracy: 0.7170 - val_loss: 0.7567 - val_accuracy: 0.8042\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 19s 70ms/step - loss: 0.7422 - accuracy: 0.8085 - val_loss: 0.7093 - val_accuracy: 0.8234\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.6932 - accuracy: 0.8325 - val_loss: 0.6669 - val_accuracy: 0.8522\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 19s 73ms/step - loss: 0.6742 - accuracy: 0.8545 - val_loss: 0.6561 - val_accuracy: 0.8770\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 19s 73ms/step - loss: 0.6631 - accuracy: 0.8808 - val_loss: 0.6649 - val_accuracy: 0.9002\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.6854 - accuracy: 0.9053 - val_loss: 0.6929 - val_accuracy: 0.9254\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.7356 - accuracy: 0.9245 - val_loss: 0.7716 - val_accuracy: 0.9378\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.8194 - accuracy: 0.9386 - val_loss: 0.8545 - val_accuracy: 0.9492\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.8806 - accuracy: 0.9496 - val_loss: 1.0064 - val_accuracy: 0.9412\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.9791 - accuracy: 0.9566 - val_loss: 1.0490 - val_accuracy: 0.9594\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 1.0721 - accuracy: 0.9618 - val_loss: 1.1388 - val_accuracy: 0.9646\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 19s 73ms/step - loss: 1.1541 - accuracy: 0.9658 - val_loss: 1.2343 - val_accuracy: 0.9666\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 1.2676 - accuracy: 0.9679 - val_loss: 1.3309 - val_accuracy: 0.9669\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 1.3663 - accuracy: 0.9695 - val_loss: 1.4128 - val_accuracy: 0.9703\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 1.4305 - accuracy: 0.9716 - val_loss: 1.5045 - val_accuracy: 0.9717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odc3ECWBRbdg",
        "outputId": "ee0a0f7c-be5b-4648-b556-6e2fb43fbde6"
      },
      "source": [
        "model = model_without_wandb(\"LSTM\", 256, 256, 3, 3, 0, 0, 256, 15, \"rmsprop\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "267/267 [==============================] - 30s 88ms/step - loss: 1.2668 - accuracy: 0.7034 - val_loss: 0.8026 - val_accuracy: 0.7756\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 22s 82ms/step - loss: 0.7979 - accuracy: 0.7792 - val_loss: 0.7734 - val_accuracy: 0.7938\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.7293 - accuracy: 0.8095 - val_loss: 0.7028 - val_accuracy: 0.8240\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 21s 80ms/step - loss: 0.6981 - accuracy: 0.8283 - val_loss: 0.7009 - val_accuracy: 0.8379\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.7095 - accuracy: 0.8418 - val_loss: 0.7171 - val_accuracy: 0.8534\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 22s 82ms/step - loss: 0.7362 - accuracy: 0.8565 - val_loss: 0.7598 - val_accuracy: 0.8676\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.7699 - accuracy: 0.8709 - val_loss: 0.7876 - val_accuracy: 0.8856\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.8072 - accuracy: 0.8874 - val_loss: 0.8626 - val_accuracy: 0.8959\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.8558 - accuracy: 0.9031 - val_loss: 0.9227 - val_accuracy: 0.9118\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 0.9346 - accuracy: 0.9163 - val_loss: 1.0017 - val_accuracy: 0.9218\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 1.0046 - accuracy: 0.9285 - val_loss: 1.0658 - val_accuracy: 0.9323\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 1.0631 - accuracy: 0.9382 - val_loss: 1.1207 - val_accuracy: 0.9474\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 1.1559 - accuracy: 0.9462 - val_loss: 1.2157 - val_accuracy: 0.9491\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 1.2344 - accuracy: 0.9519 - val_loss: 1.2827 - val_accuracy: 0.9572\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 22s 81ms/step - loss: 1.2941 - accuracy: 0.9575 - val_loss: 1.3573 - val_accuracy: 0.9613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37yiYF5agSc4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}