{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbMYFP9SLI88",
        "outputId": "0d96f1dc-a82a-484c-a8bb-92cfd262fb53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8yIrcNBLgBx"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import exp\n",
        "from math import log\n",
        "numpy_rng = np.random.RandomState(1234)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aG-WhEfLrhM"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_test.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55vwJnmnL4kE"
      },
      "source": [
        "train_data_df = train_df.drop('label', axis=1)\n",
        "train_data_np = train_data_df.to_numpy()\n",
        "train_bin = np.where(train_data_np > 127, 1, 0)\n",
        "train_data = train_bin.reshape(train_bin.shape[0], 784)\n",
        "train_labels = train_df['label']\n",
        "train_data,val_data,train_labels,val_labels = train_test_split(train_data, train_labels, test_size=0.1, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMg_hs2_RV8j"
      },
      "source": [
        "test_data_df = test_df.drop('label', axis=1)\n",
        "test_data_np = test_data_df.to_numpy()\n",
        "test_bin = np.where(test_data_np > 127, 1, 0)\n",
        "test_data = test_bin.reshape(test_bin.shape[0], 784)\n",
        "test_labels = test_df['label']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpwMWgzK2aBr"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1 + np.exp(-x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixar8AQm8ISS"
      },
      "source": [
        "def eval(data,W,b):\n",
        "  return softmax(np.reshape(np.matmul(W.T,data),(10,1)) + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaR0dzi62Cx"
      },
      "source": [
        "def one_hot_encoding(l, L):\n",
        "  e = []\n",
        "  for i in range(L):\n",
        "    if i == l:\n",
        "      e.append(1)\n",
        "    else:\n",
        "      e.append(0)\n",
        "  e_y = np.asarray(e)\n",
        "  return np.reshape(e_y,(10,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34B08Li8d9v"
      },
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ1rOnOqO7YD"
      },
      "source": [
        "def train(data,labels,W,b,lr = 0.1):\n",
        "\n",
        "  t = []\n",
        "  \n",
        "  for j in range(data.shape[0]):\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "    #print(o[j])\n",
        "    #print(o)\n",
        "  for i in range(50):\n",
        "    grad_w = np.zeros([W.shape[0],W.shape[1]])\n",
        "    grad_b = np.zeros([b.shape[0],1])\n",
        "    o = []\n",
        "    for j in range(data.shape[0]):\n",
        "      o.append(eval(data[j],W,b))\n",
        "      mul2 = np.reshape((o[j]-t[j]),[10,1])\n",
        "      mul1 = np.reshape(data[j],[data[j].shape[0],1])\n",
        "      grad_w += np.matmul(mul1,mul2.T)\n",
        "      grad_b += mul2\n",
        "      W -= lr*grad_w\n",
        "      b -= lr*grad_b\n",
        "      grad_w = np.zeros([W.shape[0],W.shape[1]])\n",
        "      grad_b = np.zeros([b.shape[0],1])\n",
        "  return W,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQi36iP0Nt1L"
      },
      "source": [
        "def test(data,labels,W,b):\n",
        "  cross_entropy = 0;\n",
        "  count = 0;\n",
        "  t = []\n",
        "  o = []\n",
        "  for j in range(data.shape[0]):\n",
        "    o.append(eval(data[j],W,b))\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "    \n",
        "    index_t = np.argmax(t[j],axis = 0)\n",
        "    index_o = np.argmax(o[j],axis = 0)\n",
        "    #print(index,o[j],t[j])\n",
        "   # print(index, o[j])\n",
        "    if index_t == index_o:\n",
        "      count += 1\n",
        "  #  print(t[j][index],o[j][index])\n",
        "   # print(o[j][index_t])\n",
        "    cross_entropy -= log(o[j][index_t]+1e-300)\n",
        "  accuracy = count\n",
        "  cross_entropy = cross_entropy/data.shape[0]\n",
        "\n",
        "  return cross_entropy, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yS_uRSu09A7"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi50r4QphNxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "d634a1e0-ec9c-4423-e340-da11c6ea7f26"
      },
      "source": [
        "class RBM(object):\n",
        "    def __init__(self, input=None, n_visible=2, n_hidden=3, W=None, hbias=None, vbias=None):\n",
        "        \n",
        "        if W is None:\n",
        "            initial_W = np.random.randn(n_visible, n_hidden) * 0.01\n",
        "            W = initial_W\n",
        "\n",
        "        if hbias is None:\n",
        "            hbias = np.random.randn(n_hidden) * 0.01  # initialize h bias 0\n",
        "\n",
        "        if vbias is None:\n",
        "            vbias = np.random.randn(n_visible) * 0.01 # initialize v bias 0\n",
        "\n",
        "        self.n_visible = n_visible \n",
        "        self.n_hidden = n_hidden   \n",
        "        self.input = input\n",
        "        self.W = W\n",
        "        self.hbias = hbias\n",
        "        self.vbias = vbias\n",
        "\n",
        "    def contrastive_divergence(self, lr=0.1, k=1, input=None):\n",
        "        if input is not None:\n",
        "            self.input = input\n",
        "        \n",
        "\n",
        "        ph_mean, ph_sample = self.sample_h_given_v(self.input)\n",
        "\n",
        "        chain_start = ph_sample\n",
        "\n",
        "        for step in range(k):\n",
        "            if step == 0:\n",
        "                nv_means, nv_samples,\\\n",
        "                nh_means, nh_samples = self.gibbs_hvh(chain_start)\n",
        "            else:\n",
        "                nv_means, nv_samples,\\\n",
        "                nh_means, nh_samples = self.gibbs_hvh(nh_samples)\n",
        "\n",
        "        self.W += lr * (np.matmul(self.input.T, ph_mean) - np.matmul(nv_samples.T,nh_means))/self.input.shape[0]\n",
        "        self.vbias += lr * np.mean(self.input - nv_samples, axis=0)\n",
        "        self.hbias += lr * np.mean(ph_mean - nh_means, axis=0)\n",
        "\n",
        "    def sample_h_given_v(self, v0_sample):\n",
        "        h1_mean = self.propup(v0_sample)\n",
        "        h1_sample = numpy_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean)\n",
        "        return [h1_mean, h1_sample]\n",
        "\n",
        "\n",
        "    def sample_v_given_h(self, h0_sample):\n",
        "        v1_mean = self.propdown(h0_sample)\n",
        "        v1_sample = numpy_rng.binomial(size=v1_mean.shape, n=1, p=v1_mean) \n",
        "        return [v1_mean, v1_sample]\n",
        "\n",
        "    def propup(self, v):\n",
        "        pre_sigmoid_activation = np.dot(v, self.W) + self.hbias\n",
        "        return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "    def propdown(self, h):\n",
        "        pre_sigmoid_activation = np.dot(h, self.W.T) + self.vbias\n",
        "        return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "\n",
        "    def gibbs_hvh(self, h0_sample):\n",
        "\n",
        "        v1_mean, v1_sample = self.sample_v_given_h(h0_sample)\n",
        "        h1_mean, h1_sample = self.sample_h_given_v(v1_sample)\n",
        "\n",
        "        return [v1_mean, v1_sample,\n",
        "                h1_mean, h1_sample]\n",
        "\n",
        "    def get_hidden_reps(self, v,t):\n",
        "        h_v = sigmoid(np.dot(v, self.W) + self.hbias)\n",
        "        h_t = sigmoid(np.dot(t, self.W) + self.hbias)\n",
        "        #reconstructed_v = sigmoid(np.dot(h, self.W.T) + self.vbias)\n",
        "        return h_v,h_t\n",
        "        \n",
        "\n",
        "def train_rbm(rbm, v,t,learning_rate=0.05, k = 1):\n",
        "    rbm.contrastive_divergence(lr=learning_rate,k=k)\n",
        "    return rbm.get_hidden_reps(v,t)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # construct RBM\n",
        "    n_visible=784\n",
        "    n_hidden=64\n",
        "    k = 5\n",
        "    rbm = RBM(input=train_data, n_visible=n_visible, n_hidden=n_hidden)\n",
        "\n",
        "    for epoch in range(25):\n",
        "\n",
        "      hidden_rep,hidden_rep_test= train_rbm(rbm, val_data,test_data,k=k)\n",
        "      print('Training epoch: %d' %epoch)\n",
        "      \n",
        "      #W_l, b_l = train(hidden_rep,val_labels,W_l,b_l,lr=0.1)\n",
        "      loss, accuracy = train_test(hidden_rep, val_labels, hidden_rep_test,test_labels)\n",
        "      print('Loss:{} Accuracy:{}'.format(loss,accuracy))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch: 0\n",
            "Loss:1.0965067955625127 Accuracy:0.6572\n",
            "Training epoch: 1\n",
            "Loss:1.2802919785876252 Accuracy:0.6305\n",
            "Training epoch: 2\n",
            "Loss:1.714053384608428 Accuracy:0.5133\n",
            "Training epoch: 3\n",
            "Loss:1.1920651200996626 Accuracy:0.6456\n",
            "Training epoch: 4\n",
            "Loss:2.0510004285549104 Accuracy:0.2857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7053b4496531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0mhidden_rep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_rep_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_rbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training epoch: %d'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7053b4496531>\u001b[0m in \u001b[0;36mtrain_rbm\u001b[0;34m(rbm, v, t, learning_rate, k)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_rbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrastive_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hidden_reps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7053b4496531>\u001b[0m in \u001b[0;36mcontrastive_divergence\u001b[0;34m(self, lr, k, input)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mnv_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv_samples\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0mnh_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgibbs_hvh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mnv_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnv_samples\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0mnh_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgibbs_hvh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnh_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7053b4496531>\u001b[0m in \u001b[0;36mgibbs_hvh\u001b[0;34m(self, h0_sample)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgibbs_hvh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mv1_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_v_given_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mh1_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_h_given_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7053b4496531>\u001b[0m in \u001b[0;36msample_v_given_h\u001b[0;34m(self, h0_sample)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_v_given_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mv1_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mv1_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv1_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv1_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv1_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTQ9Oyn84DpU"
      },
      "source": [
        "def swp():\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhXh0oIRuYlE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}