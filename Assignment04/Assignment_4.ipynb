{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbMYFP9SLI88",
        "outputId": "c2a701ac-3c41-49bb-d262-3fb363b780d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8yIrcNBLgBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "0173288b-49d0-40ac-e263-ede7e58a4fd7"
      },
      "source": [
        "!pip install wandb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import exp\n",
        "from math import log\n",
        "numpy_rng = np.random.RandomState(1234)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 21.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=45ece4223b5aed891758c682cca72b927e550276fc923fcede0a0219ca692c1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=da84345e62ccaad6b8c45ce367cea414aa851de0319a35a71ca3c08ceb5c685e\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: docker-pycreds, smmap, gitdb, GitPython, pathtools, configparser, shortuuid, subprocess32, sentry-sdk, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdW6Qq7Bgmh",
        "outputId": "683874dc-0e5e-46a1-d6bf-b4532773497d"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkodikarthik21\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aG-WhEfLrhM"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_test.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55vwJnmnL4kE"
      },
      "source": [
        "train_data_df = train_df.drop('label', axis=1)\n",
        "train_data_np = train_data_df.to_numpy()\n",
        "train_bin = np.where(train_data_np > 127, 1, 0)\n",
        "train_data = train_bin.reshape(train_bin.shape[0], 784)\n",
        "train_labels = train_df['label']\n",
        "train_data,val_data,train_labels,val_labels = train_test_split(train_data, train_labels, test_size=0.1, random_state=42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWv07zMswgqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eeba1b7-35ca-4434-9f02-d988538bad45"
      },
      "source": [
        "val_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMg_hs2_RV8j"
      },
      "source": [
        "test_data_df = test_df.drop('label', axis=1)\n",
        "test_data_np = test_data_df.to_numpy()\n",
        "test_bin = np.where(test_data_np > 127, 1, 0)\n",
        "test_data = test_bin.reshape(test_bin.shape[0], 784)\n",
        "test_labels = test_df['label']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpwMWgzK2aBr"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1 + np.exp(-x))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixar8AQm8ISS"
      },
      "source": [
        "def eval(data,W,b):\n",
        "  return softmax(np.reshape(np.matmul(W.T,data),(10,1)) + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaR0dzi62Cx"
      },
      "source": [
        "def one_hot_encoding(l, L):\n",
        "  e = []\n",
        "  for i in range(L):\n",
        "    if i == l:\n",
        "      e.append(1)\n",
        "    else:\n",
        "      e.append(0)\n",
        "  e_y = np.asarray(e)\n",
        "  return np.reshape(e_y,(10,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34B08Li8d9v"
      },
      "source": [
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ1rOnOqO7YD"
      },
      "source": [
        "def train(data,labels,W,b,lr = 0.1):\n",
        "\n",
        "  t = []\n",
        "  \n",
        "  for j in range(data.shape[0]):\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "    #print(o[j])\n",
        "    #print(o)\n",
        "  for i in range(50):\n",
        "    grad_w = np.zeros([W.shape[0],W.shape[1]])\n",
        "    grad_b = np.zeros([b.shape[0],1])\n",
        "    o = []\n",
        "    for j in range(data.shape[0]):\n",
        "      o.append(eval(data[j],W,b))\n",
        "      mul2 = np.reshape((o[j]-t[j]),[10,1])\n",
        "      mul1 = np.reshape(data[j],[data[j].shape[0],1])\n",
        "      grad_w += np.matmul(mul1,mul2.T)\n",
        "      grad_b += mul2\n",
        "      W -= lr*grad_w\n",
        "      b -= lr*grad_b\n",
        "      grad_w = np.zeros([W.shape[0],W.shape[1]])\n",
        "      grad_b = np.zeros([b.shape[0],1])\n",
        "  return W,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQi36iP0Nt1L"
      },
      "source": [
        "def test(data,labels,W,b):\n",
        "  cross_entropy = 0;\n",
        "  count = 0;\n",
        "  t = []\n",
        "  o = []\n",
        "  for j in range(data.shape[0]):\n",
        "    o.append(eval(data[j],W,b))\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "    \n",
        "    index_t = np.argmax(t[j],axis = 0)\n",
        "    index_o = np.argmax(o[j],axis = 0)\n",
        "    #print(index,o[j],t[j])\n",
        "   # print(index, o[j])\n",
        "    if index_t == index_o:\n",
        "      count += 1\n",
        "  #  print(t[j][index],o[j][index])\n",
        "   # print(o[j][index_t])\n",
        "    cross_entropy -= log(o[j][index_t]+1e-300)\n",
        "  accuracy = count\n",
        "  cross_entropy = cross_entropy/data.shape[0]\n",
        "\n",
        "  return cross_entropy, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yS_uRSu09A7"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,log_loss\n",
        "def train_test(x_train, y_train, x_test,y_test):\n",
        "  logisticRegr = LogisticRegression(max_iter = 1000,multi_class='multinomial')\n",
        "  logisticRegr.fit(x_train, y_train)\n",
        "  #print(logisticRegr.classes_)\n",
        "  y_pred = logisticRegr.predict(x_test)\n",
        "  pred = logisticRegr.predict_proba(x_test)\n",
        "  #print(y_pred)\n",
        "  #print(y_test)\n",
        "  loss = log_loss(y_test,pred)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return loss, accuracy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi50r4QphNxf"
      },
      "source": [
        "class RBM(object):\n",
        "    def __init__(self, input=None, n_visible=2, n_hidden=3, W=None, hbias=None, vbias=None):\n",
        "        \n",
        "        if W is None:\n",
        "            initial_W = np.random.randn(n_visible, n_hidden) * 0.01\n",
        "            W = initial_W\n",
        "\n",
        "        if hbias is None:\n",
        "            hbias = np.random.randn(n_hidden) * 0.01  # initialize h bias 0\n",
        "\n",
        "        if vbias is None:\n",
        "            vbias = np.random.randn(n_visible) * 0.01 # initialize v bias 0\n",
        "\n",
        "        self.n_visible = n_visible \n",
        "        self.n_hidden = n_hidden   \n",
        "        self.input = input\n",
        "        self.W = W\n",
        "        self.hbias = hbias\n",
        "        self.vbias = vbias\n",
        "\n",
        "def contrastive_divergence(rbm, lr=0.1, k=1, input=None):\n",
        "    if input is not None:\n",
        "        rbm.input = input\n",
        "    \n",
        "\n",
        "    ph_mean, ph_sample = sample_h_given_v(rbm,rbm.input)\n",
        "\n",
        "    chain_start = ph_sample\n",
        "\n",
        "    for step in range(k):\n",
        "        if step == 0:\n",
        "            nv_means, nv_samples,\\\n",
        "            nh_means, nh_samples = gibbs_hvh(rbm,chain_start)\n",
        "        else:\n",
        "            nv_means, nv_samples,\\\n",
        "            nh_means, nh_samples = gibbs_hvh(rbm,nh_samples)\n",
        "\n",
        "    rbm.W += lr * (np.matmul(rbm.input.T, ph_mean) - np.matmul(nv_samples.T,nh_means))/rbm.input.shape[0]\n",
        "    rbm.vbias += lr * np.mean(rbm.input - nv_samples, axis=0)\n",
        "    rbm.hbias += lr * np.mean(ph_mean - nh_means, axis=0)\n",
        "\n",
        "def sample_h_given_v(rbm, v0_sample):\n",
        "    h1_mean = propup(rbm,v0_sample)\n",
        "    h1_sample = numpy_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean)\n",
        "    return [h1_mean, h1_sample]\n",
        "\n",
        "\n",
        "def sample_v_given_h(rbm, h0_sample):\n",
        "    v1_mean = propdown(rbm,h0_sample)\n",
        "    v1_sample = numpy_rng.binomial(size=v1_mean.shape, n=1, p=v1_mean) \n",
        "    return [v1_mean, v1_sample]\n",
        "\n",
        "def propup(rbm, v):\n",
        "    pre_sigmoid_activation = np.dot(v, rbm.W) + rbm.hbias\n",
        "    return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "def propdown(rbm, h):\n",
        "    pre_sigmoid_activation = np.dot(h, rbm.W.T) + rbm.vbias\n",
        "    return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "\n",
        "def gibbs_hvh(rbm, h0_sample):\n",
        "\n",
        "    v1_mean, v1_sample = sample_v_given_h(rbm,h0_sample)\n",
        "    h1_mean, h1_sample = sample_h_given_v(rbm,v1_sample)\n",
        "\n",
        "    return [v1_mean, v1_sample,\n",
        "            h1_mean, h1_sample]\n",
        "\n",
        "def get_hidden_reps(rbm, v,t):\n",
        "    h_v = sigmoid(np.dot(v, rbm.W) + rbm.hbias)\n",
        "    h_t = sigmoid(np.dot(t, rbm.W) + rbm.hbias)\n",
        "    #reconstructed_v = sigmoid(np.dot(h, rbm.W.T) + rbm.vbias)\n",
        "    return h_v,h_t\n",
        "        \n",
        "\n",
        "def train_rbm(rbm, v,t,learning_rate=0.05, k = 1):\n",
        "    contrastive_divergence(rbm,lr=learning_rate,k=k)\n",
        "    return get_hidden_reps(rbm,v,t)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTQ9Oyn84DpU"
      },
      "source": [
        "def swp():\n",
        "  hyperparameter_defaults = dict(\n",
        "    n_hidden=64,\n",
        "    k = 5\n",
        "  )\n",
        "\n",
        "  wandb.init(project=\"Assignment-4\", config=hyperparameter_defaults)\n",
        "  config = wandb.config\n",
        "  wandb.run.name = \"{}_h_layers_{}_steps\".format(config.n_hidden, config.k)\n",
        "  n_visible=784\n",
        "  rbm = RBM(input=train_data, n_visible=n_visible, n_hidden=config.n_hidden)\n",
        "\n",
        "  for epoch in range(25):\n",
        "\n",
        "    hidden_rep,hidden_rep_test= train_rbm(rbm, val_data,test_data,k=config.k)\n",
        "    print('Training epoch: %d' %epoch)\n",
        "    \n",
        "    #W_l, b_l = train(hidden_rep,val_labels,W_l,b_l,lr=0.1)\n",
        "    loss, accuracy = train_test(hidden_rep, val_labels, hidden_rep_test,test_labels)\n",
        "    print('Loss:{} Accuracy:{}'.format(loss,accuracy))\n",
        "    metrics = {'epoch':epoch, 'accuracy': accuracy, 'loss': loss}\n",
        "    wandb.log(metrics)\n",
        "  wandb.run.finish()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhXh0oIRuYlE"
      },
      "source": [
        "  \"name\": \"Sweep - CD\",\n",
        "  \"method\": \"grid\",\n",
        "  \"project\": \"Assignment-4\",\n",
        "  \"metric\":{\n",
        "      \"name\":\"val_accuracy\",\n",
        "      \"goal\":\"maximize\"\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \"n_hidden\": {\n",
        "            \"values\":[64,128,256]\n",
        "        },\n",
        "        \"k\": {\n",
        "            \"values\":[1,5,10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}