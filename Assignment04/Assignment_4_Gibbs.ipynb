{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4-Gibbs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbMYFP9SLI88",
        "outputId": "1788084f-4234-4d32-9779-c037859439c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8yIrcNBLgBx"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import exp\n",
        "from math import log\n",
        "numpy_rng = np.random.RandomState(1234)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aG-WhEfLrhM"
      },
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Fashion_MNIST/fashion-mnist_test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55vwJnmnL4kE"
      },
      "source": [
        "train_data_df = train_df.drop('label', axis=1)\n",
        "train_data_np = train_data_df.to_numpy()\n",
        "train_bin = np.where(train_data_np > 127, 1, 0)\n",
        "train_data = train_bin.reshape(train_bin.shape[0], 784)\n",
        "train_labels = train_df['label'].to_frame().to_numpy()\n",
        "train_data,val_data,train_labels,val_labels = train_test_split(train_data, train_labels, test_size=0.1, random_state=42)\n",
        "#train_data = [train_data[i].flatten() for i in range(train_data.shape[0])]\n",
        "#train_data = [np.reshape(train_data[i],(1,train_data[i].shape[0])) for i in range(len(train_data))]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWv07zMswgqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e38867-d792-4069-8d2b-f82eca6195a0"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMg_hs2_RV8j"
      },
      "source": [
        "test_data_df = test_df.drop('label', axis=1)\n",
        "test_data_np = test_data_df.to_numpy()\n",
        "test_bin = np.where(test_data_np > 127, 1, 0)\n",
        "test_data = test_bin.reshape(test_bin.shape[0], 784)\n",
        "test_labels = test_df['label'].to_frame().to_numpy()\n",
        "#test_data = [test_data[i].flatten() for i in range(test_data.shape[0])]\n",
        "#test_data = [np.reshape(test_data[i],(1,test_data[i].shape[0])) for i in range(len(test_data))]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixar8AQm8ISS"
      },
      "source": [
        "def eval(data,W,b):\n",
        "  return softmax(np.reshape(np.matmul(W.T,data),(10,1)) + b)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RaR0dzi62Cx"
      },
      "source": [
        "def one_hot_encoding(l, L):\n",
        "  import numpy\n",
        "  e = []\n",
        "  for i in range(L):\n",
        "    if i == l:\n",
        "      e.append(1)\n",
        "    else:\n",
        "      e.append(0)\n",
        "  e_y = np.asarray(e)\n",
        "  return np.reshape(e_y,(10,1))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R34B08Li8d9v"
      },
      "source": [
        "def softmax(vector):\n",
        "\te = exp(vector)\n",
        "\treturn e / e.sum()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ1rOnOqO7YD"
      },
      "source": [
        "def train(data,labels,W,b,lr = 0.05):\n",
        "\n",
        "  t = []\n",
        "  o = []\n",
        "  for j in range(data.shape[0]):\n",
        "    o.append(eval(data[j],W,b))\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "  for i in range(10):\n",
        "    grad_w = np.zeros([W.shape[0],W.shape[1]])\n",
        "    grad_b = np.zeros([b.shape[0],1])\n",
        "    for j in range(data.shape[0]):\n",
        "      mul2 = np.reshape((o[j]-t[j]),[10,1])\n",
        "      mul1 = np.reshape(data[j],[32,1])\n",
        "      grad_w += np.matmul(mul1,mul2.T)\n",
        "      grad_b += mul2\n",
        "    W = W - lr*grad_w\n",
        "    b = b - lr*grad_b\n",
        "  \n",
        "  return W,b"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQi36iP0Nt1L"
      },
      "source": [
        "def test(data,labels,W,b):\n",
        "  cross_entropy = 0;\n",
        "  count = 0;\n",
        "  t = []\n",
        "  o = []\n",
        "  for j in range(data.shape[0]):\n",
        "    o.append(eval(data[j],W,b))\n",
        "    t.append(one_hot_encoding(labels[j],10))\n",
        "    index_t = np.argmax(t[j],axis = 0)\n",
        "    index_o = np.argmax(o[j],axis = 0)\n",
        "    if index_t == index_o:\n",
        "      count += 1\n",
        "    cross_entropy -= log(o[j][index_t]+1e-300)\n",
        "  accuracy = count/data.shape[0]\n",
        "\n",
        "  return cross_entropy, accuracy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kONCq2R7BVCu"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,log_loss\n",
        "def train_test(x_train, y_train, x_test,y_test):\n",
        "  logisticRegr = LogisticRegression(max_iter = 1000,multi_class='multinomial')\n",
        "  logisticRegr.fit(x_train, y_train)\n",
        "  #print(logisticRegr.classes_)\n",
        "  y_pred = logisticRegr.predict(x_test)\n",
        "  pred = logisticRegr.predict_proba(x_test)\n",
        "  #print(y_pred)\n",
        "  #print(y_test)\n",
        "  loss = log_loss(y_test,pred)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  return loss, accuracy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUkzDDVYCmnU",
        "outputId": "4cbb0f71-4dec-44a5-f47e-e0f4b7bc81d8"
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1. / (1 + np.exp(-x))\n",
        "\n",
        "numpy.seterr(all='ignore')\n",
        "\n",
        "class RBM(object):\n",
        "     def __init__(self, input=None, n_visible=2, n_hidden=3, W=None, hbias=None, vbias=None):\n",
        "        \n",
        "        if W is None:\n",
        "            initial_W = np.random.randn(n_visible, n_hidden) * 0.01\n",
        "            W = initial_W\n",
        "\n",
        "        if hbias is None:\n",
        "            hbias = np.random.randn(n_hidden) * 0.01  # initialize h bias 0\n",
        "\n",
        "        if vbias is None:\n",
        "            vbias = np.random.randn(n_visible) * 0.01 # initialize v bias 0\n",
        "\n",
        "        self.n_visible = n_visible \n",
        "        self.n_hidden = n_hidden   \n",
        "        self.input = input\n",
        "        self.W = W\n",
        "        self.hbias = hbias\n",
        "        self.vbias = vbias\n",
        "\n",
        "def gibbs_sampling(rbm, lr=0.1, k=200, r=10):\n",
        "\n",
        "  ph_mean, ph_sample = sample_h_given_v(rbm,np.random.randn(rbm.input.shape[0], rbm.input.shape[1]))\n",
        "\n",
        "  chain_start = ph_sample\n",
        "\n",
        "  for step in range(k):\n",
        "      print(\"Sampling k={}\".format(step))\n",
        "      if step == 0:\n",
        "          nv_means, nv_samples,\\\n",
        "          nh_means, nh_samples = gibbs_hvh(rbm,chain_start)\n",
        "      else:\n",
        "          nv_means, nv_samples,\\\n",
        "          nh_means, nh_samples = gibbs_hvh(rbm,nh_samples)\n",
        "  \n",
        "  dW_2 = numpy.zeros((n_visible,n_hidden))\n",
        "  dvbias_2 = numpy.zeros(n_visible)\n",
        "  dhbias_2 = numpy.zeros(n_hidden)\n",
        "\n",
        "  for step in range(r):\n",
        "    print(\"Sampling r={}\".format(step))\n",
        "    nv_means, nv_samples,\\\n",
        "    nh_means, nh_samples = gibbs_hvh(rbm,nh_samples)\n",
        "    dW_2 += numpy.dot(nv_samples.T, nh_means)\n",
        "    dvbias_2 += numpy.sum(nv_samples, axis=0)\n",
        "    dhbias_2 += numpy.sum(nh_means, axis=0)\n",
        "\n",
        "  # chain_end = nv_samples\n",
        "  rbm.W += lr * (numpy.dot(rbm.input.T, ph_mean)\n",
        "                  - dW_2)\n",
        "  rbm.vbias += lr * numpy.mean(rbm.input - dvbias_2, axis=0)\n",
        "  rbm.hbias += lr * numpy.mean(ph_sample - dhbias_2, axis=0)\n",
        "\n",
        "def sample_h_given_v(rbm, v0_sample):\n",
        "    h1_mean = propup(rbm,v0_sample)\n",
        "    h1_sample = numpy_rng.binomial(size=h1_mean.shape, n=1, p=h1_mean)\n",
        "    return [h1_mean, h1_sample]\n",
        "\n",
        "\n",
        "def sample_v_given_h(rbm, h0_sample):\n",
        "    v1_mean = propdown(rbm,h0_sample)\n",
        "    v1_sample = numpy_rng.binomial(size=v1_mean.shape, n=1, p=v1_mean) \n",
        "    return [v1_mean, v1_sample]\n",
        "\n",
        "def propup(rbm, v):\n",
        "    pre_sigmoid_activation = np.dot(v, rbm.W) + rbm.hbias\n",
        "    return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "def propdown(rbm, h):\n",
        "    pre_sigmoid_activation = np.dot(h, rbm.W.T) + rbm.vbias\n",
        "    return sigmoid(pre_sigmoid_activation)\n",
        "\n",
        "\n",
        "def gibbs_hvh(rbm, h0_sample):\n",
        "\n",
        "    v1_mean, v1_sample = sample_v_given_h(rbm,h0_sample)\n",
        "    h1_mean, h1_sample = sample_h_given_v(rbm,v1_sample)\n",
        "\n",
        "    return [v1_mean, v1_sample,\n",
        "            h1_mean, h1_sample]\n",
        "\n",
        "def get_hidden_reps(rbm, v,t):\n",
        "    h_v = sigmoid(np.dot(v, rbm.W) + rbm.hbias)\n",
        "    h_t = sigmoid(np.dot(t, rbm.W) + rbm.hbias)\n",
        "    #reconstructed_v = sigmoid(np.dot(h, rbm.W.T) + rbm.vbias)\n",
        "    return h_v,h_t\n",
        "        \n",
        "\n",
        "def train_rbm(rbm, v,t,learning_rate=0.05, k = 200, r=10):\n",
        "    gibbs_sampling(rbm,lr=learning_rate,k=k,r=r)\n",
        "    return get_hidden_reps(rbm,v,t)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # construct RBM\n",
        "    n_visible=784\n",
        "    n_hidden=32\n",
        "    rbm = RBM(input=train_data, n_visible=n_visible, n_hidden=n_hidden)\n",
        "    for epoch in range(5):\n",
        "      hidden_rep,hidden_rep_test= train_rbm(rbm,val_data,test_data,k=10,r=1)\n",
        "      print('Training epoch: %d' %epoch)\n",
        "      \n",
        "      #W_l, b_l = train(hidden_rep,val_labels,W_l,b_l,lr=0.1)\n",
        "      loss, accuracy = train_test(hidden_rep, val_labels, hidden_rep_test,test_labels)\n",
        "      print('Loss:{} Accuracy:{}'.format(loss,accuracy))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sampling k=0\n",
            "Sampling k=1\n",
            "Sampling k=2\n",
            "Sampling k=3\n",
            "Sampling k=4\n",
            "Sampling k=5\n",
            "Sampling k=6\n",
            "Sampling k=7\n",
            "Sampling k=8\n",
            "Sampling k=9\n",
            "Sampling r=0\n",
            "Training epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:1.9945485598547896 Accuracy:0.2484\n",
            "Sampling k=0\n",
            "Sampling k=1\n",
            "Sampling k=2\n",
            "Sampling k=3\n",
            "Sampling k=4\n",
            "Sampling k=5\n",
            "Sampling k=6\n",
            "Sampling k=7\n",
            "Sampling k=8\n",
            "Sampling k=9\n",
            "Sampling r=0\n",
            "Training epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:1.7218605155431659 Accuracy:0.3158\n",
            "Sampling k=0\n",
            "Sampling k=1\n",
            "Sampling k=2\n",
            "Sampling k=3\n",
            "Sampling k=4\n",
            "Sampling k=5\n",
            "Sampling k=6\n",
            "Sampling k=7\n",
            "Sampling k=8\n",
            "Sampling k=9\n",
            "Sampling r=0\n",
            "Training epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:1.944450082494686 Accuracy:0.2678\n",
            "Sampling k=0\n",
            "Sampling k=1\n",
            "Sampling k=2\n",
            "Sampling k=3\n",
            "Sampling k=4\n",
            "Sampling k=5\n",
            "Sampling k=6\n",
            "Sampling k=7\n",
            "Sampling k=8\n",
            "Sampling k=9\n",
            "Sampling r=0\n",
            "Training epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:1.754669859877737 Accuracy:0.3433\n",
            "Sampling k=0\n",
            "Sampling k=1\n",
            "Sampling k=2\n",
            "Sampling k=3\n",
            "Sampling k=4\n",
            "Sampling k=5\n",
            "Sampling k=6\n",
            "Sampling k=7\n",
            "Sampling k=8\n",
            "Sampling k=9\n",
            "Sampling r=0\n",
            "Training epoch: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:2.15976536251928 Accuracy:0.2031\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}